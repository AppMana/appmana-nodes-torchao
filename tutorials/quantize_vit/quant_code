/scratch/cpuhrsch/miniconda3/envs/nightly20240311py310/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/scratch/cpuhrsch/miniconda3/envs/nightly20240311py310/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] Output code: 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from ctypes import c_void_p, c_long
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] import torch
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] import math
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] import random
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] import os
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] import tempfile
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from math import inf, nan
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.hooks import run_intermediate_hooks
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.utils import maybe_profile
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.codegen.memory_planning import _align as align
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch import device, empty_strided
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.codecache import AsyncCompile
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.select_algorithm import extern_kernels
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.codegen.multi_kernel import MultiKernelCall
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] aten = torch.ops.aten
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] inductor_ops = torch.ops.inductor
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] reinterpret_tensor = torch.ops.inductor._reinterpret_tensor
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] async_compile = AsyncCompile()
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] # kernel path: /tmp/torchinductor_cpuhrsch/xo/cxomyq2r4dpiacnrptiwyakoztfh6gd3tdnxedkefsy6sa5fbope.py
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] # Source Nodes: [cat_1, input_1, x_5], Original ATen: [aten.add, aten.cat, aten.native_layer_norm]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] # cat_1 => cat
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] # input_1 => add
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] # x_5 => add_1, add_2, convert_element_type, convert_element_type_1, mul, mul_1, rsqrt, sub, var_mean
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] triton_per_fused_add_cat_native_layer_norm_0 = async_compile.triton('triton_', '''
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] import triton
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] import triton.language as tl
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor import triton_helpers, triton_heuristics
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.ir import ReductionHint, TileHint
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.triton_helpers import libdevice, math as tl_math
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.triton_heuristics import AutotuneHint
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.utils import instance_descriptor
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] @triton_heuristics.persistent_reduction(
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     size_hints=[256, 1024],
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     filename=__file__,
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     triton_meta={'signature': {0: '*fp32', 1: '*bf16', 2: '*bf16', 3: '*bf16', 4: '*bf16', 5: '*bf16', 6: '*bf16', 7: '*bf16', 8: '*fp32', 9: '*bf16', 10: 'i32', 11: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11), equal_to_1=(), divisible_by_8=(11,))]},
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_cat_native_layer_norm_0', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': True, 'backend_hash': '3259a14c125f5ba3dada77d918425e716ee1128895f1ea33af731e8e188c796e'}
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] )
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] @triton.jit
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel):
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     xnumel = 197
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     XBLOCK: tl.constexpr = 1
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     rnumel = 768
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     RBLOCK: tl.constexpr = 1024
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     xindex = tl.full([1], xoffset, tl.int32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     xmask = xindex < xnumel
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     rindex = tl.arange(0, RBLOCK)[:]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     roffset = 0
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     rmask = rindex < rnumel
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     x0 = xindex
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     r1 = rindex
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp17 = tl.load(in_ptr3 + (r1 + (768*x0)), rmask & xmask, other=0.0).to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp43 = tl.load(in_ptr4 + (r1), rmask, eviction_policy='evict_last', other=0.0).to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp46 = tl.load(in_ptr5 + (r1), rmask, eviction_policy='evict_last', other=0.0).to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp0 = x0
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp1 = tl.full([1], 0, tl.int64)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp2 = tmp0 >= tmp1
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp3 = tl.full([1], 1, tl.int64)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp4 = tmp0 < tmp3
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp5 = tl.load(in_ptr0 + (tl.broadcast_to(r1, [RBLOCK])), rmask & tmp4 & xmask, eviction_policy='evict_last', other=0.0).to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp6 = tl.full(tmp5.shape, 0.0, tmp5.dtype)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp7 = tl.where(tmp4, tmp5, tmp6)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp8 = tmp0 >= tmp3
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp9 = tl.full([1], 197, tl.int64)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp10 = tmp0 < tmp9
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp11 = tl.load(in_ptr1 + ((196*r1) + (((-1) + x0) % 196)), rmask & tmp8 & xmask, eviction_policy='evict_last', other=0.0).to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp12 = tl.load(in_ptr2 + (tl.broadcast_to(r1, [RBLOCK])), rmask & tmp8 & xmask, eviction_policy='evict_last', other=0.0).to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp13 = tmp11 + tmp12
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp14 = tl.full(tmp13.shape, 0.0, tmp13.dtype)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp15 = tl.where(tmp8, tmp13, tmp14)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp16 = tl.where(tmp4, tmp7, tmp15)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp18 = tmp16 + tmp17
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp19 = tmp18.to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp20 = tl.broadcast_to(tmp19, [RBLOCK])
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp22 = tl.where(rmask & xmask, tmp20, 0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp23 = tl.broadcast_to(tmp20, [RBLOCK])
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp25 = tl.where(rmask & xmask, tmp23, 0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp26 = triton_helpers.promote_to_tensor(tl.sum(tmp25, 0))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp27 = tl.full([1], 768, tl.int32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp28 = tmp27.to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp29 = tmp26 / tmp28
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp30 = tmp20 - tmp29
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp31 = tmp30 * tmp30
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp32 = tl.broadcast_to(tmp31, [RBLOCK])
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp34 = tl.where(rmask & xmask, tmp32, 0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp35 = triton_helpers.promote_to_tensor(tl.sum(tmp34, 0))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp36 = 768.0
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp37 = tmp35 / tmp36
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp38 = 1e-06
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp39 = tmp37 + tmp38
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp40 = libdevice.rsqrt(tmp39)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp41 = tmp19 - tmp29
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp42 = tmp41 * tmp40
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp44 = tmp43.to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp45 = tmp42 * tmp44
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp47 = tmp46.to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp48 = tmp45 + tmp47
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp49 = tmp48.to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tl.store(out_ptr0 + (r1 + (768*x0)), tmp18, rmask & xmask)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tl.debug_barrier()
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp40, xmask)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tl.store(out_ptr2 + (r1 + (768*x0)), tmp49, rmask & xmask)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp29, xmask)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] ''', device_str='cuda')
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] import triton
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] import triton.language as tl
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.triton_heuristics import grid, split_scan_grid, start_graph, end_graph
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] # kernel path: /tmp/torchinductor_cpuhrsch/yg/cygv3vdqh4xmwyvw2ljgybrsoo3gediwvjhepxlktzsuiviko5hd.py
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] # Source Nodes: [l__self___encoder_layers_encoder_layer_0_self_attention], Original ATen: [aten.clone]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] # l__self___encoder_layers_encoder_layer_0_self_attention => clone_1
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] triton_poi_fused_clone_1 = async_compile.triton('triton_', '''
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] import triton
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] import triton.language as tl
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor import triton_helpers, triton_heuristics
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.ir import ReductionHint, TileHint
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.triton_helpers import libdevice, math as tl_math
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.triton_heuristics import AutotuneHint
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.utils import instance_descriptor
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] @triton_heuristics.pointwise(
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     size_hints=[524288], 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     filename=__file__,
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     triton_meta={'signature': {0: '*bf16', 1: '*bf16', 2: '*bf16', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=(), divisible_by_8=(3,))]},
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_clone_1', 'mutated_arg_names': [], 'no_x_dim': False, 'backend_hash': '3259a14c125f5ba3dada77d918425e716ee1128895f1ea33af731e8e188c796e'},
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     min_elem_per_thread=0
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] )
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] @triton.jit
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     xnumel = 453888
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     xmask = xindex < xnumel
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     x0 = xindex % 768
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     x1 = (xindex // 768) % 197
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     x2 = (xindex // 151296)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     x3 = xindex
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0 + (768*x2) + (2304*x1)), xmask).to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (x0 + (768*x2)), xmask, eviction_policy='evict_last').to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tl.store(out_ptr0 + (x3), tmp2, xmask)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] ''', device_str='cuda')
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] # kernel path: /tmp/torchinductor_cpuhrsch/xt/cxtlkffjwggvlectf7hcmefbiv4qowcygxmni5ik7pnbmkrptqiq.py
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] # Source Nodes: [l__self___encoder_layers_encoder_layer_0_self_attention], Original ATen: [aten._to_copy, aten.abs, aten.amax, aten.clamp, aten.div, aten.round]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] # l__self___encoder_layers_encoder_layer_0_self_attention => abs_1, amax, clamp_max, clamp_min, clamp_min_1, convert_element_type_5, convert_element_type_6, convert_element_type_7, convert_element_type_8, convert_element_type_9, div, div_1, round_1
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] triton_per_fused__to_copy_abs_amax_clamp_div_round_2 = async_compile.triton('triton_', '''
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] import triton
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] import triton.language as tl
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor import triton_helpers, triton_heuristics
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.ir import ReductionHint, TileHint
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.triton_helpers import libdevice, math as tl_math
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.triton_heuristics import AutotuneHint
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.utils import instance_descriptor
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] @triton_heuristics.persistent_reduction(
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     size_hints=[256, 1024],
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     filename=__file__,
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     triton_meta={'signature': {0: '*bf16', 1: '*i8', 2: '*bf16', 3: 'i32', 4: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 4), equal_to_1=(), divisible_by_8=(4,))]},
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused__to_copy_abs_amax_clamp_div_round_2', 'mutated_arg_names': [], 'no_x_dim': True, 'backend_hash': '3259a14c125f5ba3dada77d918425e716ee1128895f1ea33af731e8e188c796e'}
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] )
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] @triton.jit
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] def triton_(in_ptr0, out_ptr1, out_ptr2, xnumel, rnumel):
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     xnumel = 197
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     XBLOCK: tl.constexpr = 1
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     rnumel = 768
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     RBLOCK: tl.constexpr = 1024
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     xindex = tl.full([1], xoffset, tl.int32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     xmask = xindex < xnumel
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     rindex = tl.arange(0, RBLOCK)[:]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     roffset = 0
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     rmask = rindex < rnumel
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     r1 = rindex
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     x0 = xindex
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (r1 + (768*x0)), rmask & xmask, other=0.0).to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp1 = tl_math.abs(tmp0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp2 = tl.broadcast_to(tmp1, [RBLOCK])
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp4 = tl.where(rmask & xmask, tmp2, float("-inf"))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp5 = triton_helpers.promote_to_tensor(triton_helpers.max2(tmp4, 0))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp6 = tmp5.to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp7 = 1e-05
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp8 = triton_helpers.maximum(tmp6, tmp7)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp9 = tmp8.to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp10 = 127.0
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp11 = tmp9 / tmp10
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp12 = tmp0 / tmp11
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp13 = libdevice.nearbyint(tmp12)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp14 = tmp13.to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp15 = -127.0
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp16 = triton_helpers.maximum(tmp14, tmp15)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp17 = triton_helpers.minimum(tmp16, tmp10)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp18 = tmp17.to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp19 = tmp18.to(tl.int8)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tl.store(out_ptr1 + (r1 + (768*x0)), tmp19, rmask & xmask)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tl.store(out_ptr2 + (x0), tmp11, xmask)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] ''', device_str='cuda')
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] # kernel path: /tmp/torchinductor_cpuhrsch/vu/cvuhm7baqdowsknw3b3uwb7pjpy6brqrwcufxa7f4zgtkyjyumsv.py
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] # Source Nodes: [l__self___encoder_layers_encoder_layer_0_self_attention], Original ATen: [aten._to_copy, aten.clamp, aten.div, aten.mul, aten.round, aten.view]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] # l__self___encoder_layers_encoder_layer_0_self_attention => clamp_max, clamp_min, clamp_min_1, convert_element_type_5, convert_element_type_6, convert_element_type_7, convert_element_type_8, convert_element_type_9, div, div_1, fused_int_mm_mul_11, round_1, view_11, view_12
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] triton_tem_fused__to_copy_clamp_div_mul_round_view_3 = async_compile.triton('triton_', '''
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] import triton
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] import triton.language as tl
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor import triton_helpers, triton_heuristics
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.ir import ReductionHint, TileHint
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.triton_helpers import libdevice, math as tl_math
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.triton_heuristics import AutotuneHint
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.utils import instance_descriptor
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] @triton_heuristics.template(
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     num_stages=3,
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     num_warps=8,
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     triton_meta={'signature': {0: '*i8', 1: '*i8', 2: '*bf16', 3: '*bf16'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=(), divisible_by_8=())]},
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     inductor_meta={'kernel_name': 'triton_tem_fused__to_copy_clamp_div_mul_round_view_3', 'backend_hash': '3259a14c125f5ba3dada77d918425e716ee1128895f1ea33af731e8e188c796e'},
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] )
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] @triton.jit
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] def triton_(arg_A, arg_B, in_ptr2, out_ptr0):
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     GROUP_M : tl.constexpr = 8
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     EVEN_K : tl.constexpr = True
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     ALLOW_TF32 : tl.constexpr = False
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     ACC_TYPE : tl.constexpr = tl.int32
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     B_PROLOGUE_CAST_TYPE : tl.constexpr = None
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     BLOCK_M : tl.constexpr = 64
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     BLOCK_N : tl.constexpr = 64
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     BLOCK_K : tl.constexpr = 64
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     A = arg_A
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     B = arg_B
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     M = 197
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     N = 768
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     K = 768
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     if M * N == 0:
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # early exit due to zero-size input(s)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         return
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     stride_am = 768
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     stride_ak = 1
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     stride_bk = 1
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     stride_bn = 768
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     # based on triton.ops.matmul
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     pid = tl.program_id(0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     grid_m = (M + BLOCK_M - 1) // BLOCK_M
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     grid_n = (N + BLOCK_N - 1) // BLOCK_N
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     # re-order program ID for better L2 performance
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     width = GROUP_M * grid_n
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     group_id = pid // width
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     group_size = min(grid_m - group_id * GROUP_M, GROUP_M)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     pid_m = group_id * GROUP_M + (pid % group_size)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     pid_n = (pid % width) // (group_size)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     rm = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     rn = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     ram = tl.max_contiguous(tl.multiple_of(rm % M, BLOCK_M), BLOCK_M)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     rbn = tl.max_contiguous(tl.multiple_of(rn % N, BLOCK_N), BLOCK_N)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     rk = tl.arange(0, BLOCK_K)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     A = A + (ram[:, None] * stride_am + rk[None, :] * stride_ak)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     B = B + (rk[:, None] * stride_bk + rbn[None, :] * stride_bn)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=ACC_TYPE)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     for k in range(K, 0, -BLOCK_K):
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         if EVEN_K:
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]             a = tl.load(A)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]             b = tl.load(B)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         else:
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]             a = tl.load(A, mask=rk[None, :] < k, other=0.)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]             b = tl.load(B, mask=rk[:, None] < k, other=0.)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         if B_PROLOGUE_CAST_TYPE is not None:
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]             b = b.to(B_PROLOGUE_CAST_TYPE)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         acc += tl.dot(a, b, allow_tf32=ALLOW_TF32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         A += BLOCK_K * stride_ak
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         B += BLOCK_K * stride_bk
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     # rematerialize rm and rn to save registers
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     rm = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     rn = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     idx_m = rm[:, None]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     idx_n = rn[None, :]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     mask = (idx_m < M) & (idx_n < N)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     # inductor generates a suffix
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     xindex = idx_n + (768*idx_m)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp0 = tl.load(in_ptr2 + (tl.broadcast_to(idx_m, mask.shape)), mask, eviction_policy='evict_last').to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tl.store(out_ptr0 + (tl.broadcast_to(xindex, mask.shape)), acc * tmp0, mask)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] ''', device_str='cuda')
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] import torch._inductor.kernel.mm_common
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] meta0 = {'GROUP_M': 8, 'EVEN_K': True, 'ALLOW_TF32': False, 'ACC_TYPE': 'tl.int32', 'B_PROLOGUE_CAST_TYPE': None, 'BLOCK_M': 64, 'BLOCK_N': 64, 'BLOCK_K': 64}
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] # kernel path: /tmp/torchinductor_cpuhrsch/if/cifjqsnsidii7vo2ytpyrgqlwciqbxaiabys5faat5sfakj54j72.py
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] # Source Nodes: [l__self___encoder_layers_encoder_layer_0_mlp_0, x_7, x_8, y], Original ATen: [aten._to_copy, aten.abs, aten.add, aten.amax, aten.clamp, aten.clone, aten.div, aten.native_layer_norm, aten.round]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] # l__self___encoder_layers_encoder_layer_0_mlp_0 => abs_2, amax_1, clamp_max_1, clamp_min_2, clamp_min_3, convert_element_type_12, convert_element_type_13, convert_element_type_14, convert_element_type_15, convert_element_type_16, div_2, div_3, round_2
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] # x_7 => clone_2
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] # x_8 => add_4
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] # y => add_5, add_6, convert_element_type_10, convert_element_type_11, mul_4, mul_5, rsqrt_1, sub_1, var_mean_1
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] triton_per_fused__to_copy_abs_add_amax_clamp_clone_div_native_layer_norm_round_4 = async_compile.triton('triton_', '''
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] import triton
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] import triton.language as tl
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor import triton_helpers, triton_heuristics
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.ir import ReductionHint, TileHint
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.triton_helpers import libdevice, math as tl_math
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.triton_heuristics import AutotuneHint
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.utils import instance_descriptor
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] @triton_heuristics.persistent_reduction(
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     size_hints=[256, 1024],
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     filename=__file__,
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     triton_meta={'signature': {0: '*bf16', 1: '*fp32', 2: '*bf16', 3: '*bf16', 4: '*bf16', 5: '*bf16', 6: '*bf16', 7: '*fp32', 8: '*bf16', 9: '*bf16', 10: '*i8', 11: 'i32', 12: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12), equal_to_1=(), divisible_by_8=(12,))]},
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused__to_copy_abs_add_amax_clamp_clone_div_native_layer_norm_round_4', 'mutated_arg_names': ['in_out_ptr0', 'in_out_ptr1'], 'no_x_dim': True, 'backend_hash': '3259a14c125f5ba3dada77d918425e716ee1128895f1ea33af731e8e188c796e'}
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] )
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] @triton.jit
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] def triton_(in_out_ptr0, in_out_ptr1, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr3, xnumel, rnumel):
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     xnumel = 197
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     XBLOCK: tl.constexpr = 1
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     rnumel = 768
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     RBLOCK: tl.constexpr = 1024
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     xindex = tl.full([1], xoffset, tl.int32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     xmask = xindex < xnumel
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     rindex = tl.arange(0, RBLOCK)[:]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     roffset = 0
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     rmask = rindex < rnumel
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     r1 = rindex
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     x0 = xindex
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp0 = tl.load(in_out_ptr0 + (r1 + (768*x0)), rmask & xmask, other=0.0).to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp1 = tl.load(in_ptr0 + (r1), rmask, eviction_policy='evict_last', other=0.0).to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp3 = tl.load(in_ptr1 + (r1), rmask, eviction_policy='evict_last', other=0.0).to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp5 = tl.load(in_ptr2 + (r1 + (768*x0)), rmask & xmask, other=0.0).to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp31 = tl.load(in_ptr3 + (r1), rmask, eviction_policy='evict_last', other=0.0).to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp34 = tl.load(in_ptr4 + (r1), rmask, eviction_policy='evict_last', other=0.0).to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp2 = tmp0 * tmp1
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp4 = tmp2 + tmp3
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp6 = tmp4 + tmp5
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp7 = tmp6.to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp8 = tl.broadcast_to(tmp7, [RBLOCK])
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp10 = tl.where(rmask & xmask, tmp8, 0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp11 = tl.broadcast_to(tmp8, [RBLOCK])
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp13 = tl.where(rmask & xmask, tmp11, 0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp14 = triton_helpers.promote_to_tensor(tl.sum(tmp13, 0))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp15 = tl.full([1], 768, tl.int32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp16 = tmp15.to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp17 = tmp14 / tmp16
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp18 = tmp8 - tmp17
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp19 = tmp18 * tmp18
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp20 = tl.broadcast_to(tmp19, [RBLOCK])
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp22 = tl.where(rmask & xmask, tmp20, 0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp23 = triton_helpers.promote_to_tensor(tl.sum(tmp22, 0))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp24 = 768.0
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp25 = tmp23 / tmp24
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp26 = 1e-06
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp27 = tmp25 + tmp26
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp28 = libdevice.rsqrt(tmp27)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp29 = tmp7 - tmp17
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp30 = tmp29 * tmp28
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp32 = tmp31.to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp33 = tmp30 * tmp32
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp35 = tmp34.to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp36 = tmp33 + tmp35
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp37 = tmp36.to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp38 = tl_math.abs(tmp37)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp39 = tl.broadcast_to(tmp38, [RBLOCK])
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp41 = tl.where(rmask & xmask, tmp39, float("-inf"))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp42 = triton_helpers.promote_to_tensor(triton_helpers.max2(tmp41, 0))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp43 = tmp42.to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp44 = 1e-05
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp45 = triton_helpers.maximum(tmp43, tmp44)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp46 = tmp45.to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp47 = 127.0
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp48 = tmp46 / tmp47
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp49 = tmp37 / tmp48
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp50 = libdevice.nearbyint(tmp49)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp51 = tmp50.to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp52 = -127.0
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp53 = triton_helpers.maximum(tmp51, tmp52)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp54 = triton_helpers.minimum(tmp53, tmp47)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp55 = tmp54.to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp56 = tmp55.to(tl.int8)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tl.store(in_out_ptr0 + (r1 + (768*x0)), tmp6, rmask & xmask)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tl.debug_barrier()
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tl.store(in_out_ptr1 + (x0), tmp28, xmask)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tl.store(out_ptr1 + (r1 + (768*x0)), tmp37, rmask & xmask)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tl.store(out_ptr3 + (r1 + (768*x0)), tmp56, rmask & xmask)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp17, xmask)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tl.store(out_ptr2 + (x0), tmp42, xmask)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] ''', device_str='cuda')
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] # kernel path: /tmp/torchinductor_cpuhrsch/d3/cd3fyaa3czqdhngk2h5ijufgi6epmaveh2c4jmznbvedizrcvsuc.py
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] # Source Nodes: [l__self___encoder_layers_encoder_layer_0_mlp_0], Original ATen: [aten._int_mm]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] # l__self___encoder_layers_encoder_layer_0_mlp_0 => _int_mm_1
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] triton_tem_fused__int_mm_5 = async_compile.triton('triton_', '''
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] import triton
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] import triton.language as tl
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor import triton_helpers, triton_heuristics
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.ir import ReductionHint, TileHint
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.triton_helpers import libdevice, math as tl_math
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.triton_heuristics import AutotuneHint
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.utils import instance_descriptor
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] @triton_heuristics.template(
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     num_stages=3,
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     num_warps=8,
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     triton_meta={'signature': {0: '*i8', 1: '*i8', 2: '*i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), divisible_by_8=())]},
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     inductor_meta={'kernel_name': 'triton_tem_fused__int_mm_5', 'backend_hash': '3259a14c125f5ba3dada77d918425e716ee1128895f1ea33af731e8e188c796e'},
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] )
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] @triton.jit
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] def triton_(arg_A, arg_B, out_ptr0):
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     GROUP_M : tl.constexpr = 8
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     EVEN_K : tl.constexpr = True
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     ALLOW_TF32 : tl.constexpr = False
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     ACC_TYPE : tl.constexpr = tl.int32
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     B_PROLOGUE_CAST_TYPE : tl.constexpr = None
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     BLOCK_M : tl.constexpr = 64
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     BLOCK_N : tl.constexpr = 64
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     BLOCK_K : tl.constexpr = 64
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     A = arg_A
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     B = arg_B
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     M = 197
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     N = 3072
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     K = 768
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     if M * N == 0:
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # early exit due to zero-size input(s)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         return
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     stride_am = 768
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     stride_ak = 1
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     stride_bk = 1
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     stride_bn = 768
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     # based on triton.ops.matmul
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     pid = tl.program_id(0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     grid_m = (M + BLOCK_M - 1) // BLOCK_M
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     grid_n = (N + BLOCK_N - 1) // BLOCK_N
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     # re-order program ID for better L2 performance
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     width = GROUP_M * grid_n
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     group_id = pid // width
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     group_size = min(grid_m - group_id * GROUP_M, GROUP_M)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     pid_m = group_id * GROUP_M + (pid % group_size)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     pid_n = (pid % width) // (group_size)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     rm = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     rn = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     ram = tl.max_contiguous(tl.multiple_of(rm % M, BLOCK_M), BLOCK_M)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     rbn = tl.max_contiguous(tl.multiple_of(rn % N, BLOCK_N), BLOCK_N)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     rk = tl.arange(0, BLOCK_K)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     A = A + (ram[:, None] * stride_am + rk[None, :] * stride_ak)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     B = B + (rk[:, None] * stride_bk + rbn[None, :] * stride_bn)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=ACC_TYPE)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     for k in range(K, 0, -BLOCK_K):
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         if EVEN_K:
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]             a = tl.load(A)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]             b = tl.load(B)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         else:
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]             a = tl.load(A, mask=rk[None, :] < k, other=0.)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]             b = tl.load(B, mask=rk[:, None] < k, other=0.)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         if B_PROLOGUE_CAST_TYPE is not None:
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]             b = b.to(B_PROLOGUE_CAST_TYPE)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         acc += tl.dot(a, b, allow_tf32=ALLOW_TF32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         A += BLOCK_K * stride_ak
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         B += BLOCK_K * stride_bk
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     # rematerialize rm and rn to save registers
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     rm = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     rn = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     idx_m = rm[:, None]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     idx_n = rn[None, :]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     mask = (idx_m < M) & (idx_n < N)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     # inductor generates a suffix
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     xindex = idx_n + (3072*idx_m)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tl.store(out_ptr0 + (tl.broadcast_to(xindex, mask.shape)), acc, mask)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] ''', device_str='cuda')
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] # kernel path: /tmp/torchinductor_cpuhrsch/yd/cyddjfipxbnuvmtnqzj3mi3bbygffcrjg4bpqnd7etcq2tyf6jnr.py
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] # Source Nodes: [l__self___encoder_layers_encoder_layer_0_mlp_0, l__self___encoder_layers_encoder_layer_0_mlp_1, l__self___encoder_layers_encoder_layer_0_mlp_3], Original ATen: [aten._to_copy, aten.abs, aten.add, aten.amax, aten.clamp, aten.div, aten.gelu, aten.round]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] # l__self___encoder_layers_encoder_layer_0_mlp_0 => add_7
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] # l__self___encoder_layers_encoder_layer_0_mlp_1 => add_8, convert_element_type_17, convert_element_type_18, erf, mul_10, mul_8, mul_9
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] # l__self___encoder_layers_encoder_layer_0_mlp_3 => abs_3, amax_2, clamp_max_2, clamp_min_4, clamp_min_5, convert_element_type_19, convert_element_type_20, convert_element_type_21, convert_element_type_22, convert_element_type_23, div_4, div_5, round_3
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] triton_red_fused__to_copy_abs_add_amax_clamp_div_gelu_round_6 = async_compile.triton('triton_', '''
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] import triton
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] import triton.language as tl
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor import triton_helpers, triton_heuristics
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.ir import ReductionHint, TileHint
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.triton_helpers import libdevice, math as tl_math
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.triton_heuristics import AutotuneHint
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.utils import instance_descriptor
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] @triton_heuristics.reduction(
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     size_hints=[256, 4096],
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     filename=__file__,
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     triton_meta={'signature': {0: '*i32', 1: '*bf16', 2: '*bf16', 3: '*bf16', 4: '*bf16', 5: '*bf16', 6: '*bf16', 7: '*i8', 8: 'i32', 9: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 9), equal_to_1=(), divisible_by_8=(9,))]},
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_red_fused__to_copy_abs_add_amax_clamp_div_gelu_round_6', 'mutated_arg_names': [], 'no_x_dim': False, 'backend_hash': '3259a14c125f5ba3dada77d918425e716ee1128895f1ea33af731e8e188c796e'}
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] )
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] @triton.jit
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, out_ptr0, out_ptr1, out_ptr2, out_ptr3, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     xnumel = 197
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     rnumel = 3072
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     xmask = xindex < xnumel
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     rbase = tl.arange(0, RBLOCK)[None, :]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     x0 = xindex
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp2 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last').to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     _tmp26 = tl.full([XBLOCK, RBLOCK], float("-inf"), tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     for roffset in range(0, rnumel, RBLOCK):
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         rindex = roffset + rbase
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         rmask = rindex < rnumel
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         r1 = rindex
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (r1 + (3072*x0)), rmask & xmask, eviction_policy='evict_first', other=0.0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         tmp10 = tl.load(in_ptr2 + (r1), rmask, eviction_policy='evict_last', other=0.0).to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         tmp12 = tl.load(in_ptr3 + (r1), rmask, eviction_policy='evict_last', other=0.0).to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         tmp1 = tmp0.to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         tmp3 = tmp2.to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         tmp4 = 1e-05
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         tmp5 = triton_helpers.maximum(tmp3, tmp4)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         tmp6 = tmp5.to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         tmp7 = 127.0
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         tmp8 = tmp6 / tmp7
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         tmp9 = tmp1 * tmp8
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         tmp11 = tmp9 * tmp10
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         tmp13 = tmp11 + tmp12
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         tmp14 = tmp13.to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         tmp15 = 0.5
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         tmp16 = tmp14 * tmp15
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         tmp17 = 0.7071067811865476
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         tmp18 = tmp14 * tmp17
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         tmp19 = libdevice.erf(tmp18)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         tmp20 = 1.0
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         tmp21 = tmp19 + tmp20
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         tmp22 = tmp16 * tmp21
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         tmp23 = tmp22.to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         tmp24 = tl_math.abs(tmp23)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         tmp25 = tl.broadcast_to(tmp24, [XBLOCK, RBLOCK])
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         tmp27 = triton_helpers.maximum(_tmp26, tmp25)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         _tmp26 = tl.where(rmask & xmask, tmp27, _tmp26)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         tl.store(out_ptr0 + (r1 + (3072*x0)), tmp13, rmask & xmask)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         tl.store(out_ptr1 + (r1 + (3072*x0)), tmp23, rmask & xmask)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp26 = triton_helpers.max2(_tmp26, 1)[:, None]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tl.store(out_ptr2 + (x0), tmp26, xmask)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     for roffset in range(0, rnumel, RBLOCK):
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         rindex = roffset + rbase
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         rmask = rindex < rnumel
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         r1 = rindex
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         tmp28 = tl.load(out_ptr1 + (r1 + (3072*x0)), rmask & xmask, eviction_policy='evict_first', other=0.0).to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         tmp29 = tmp26.to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         tmp30 = 1e-05
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         tmp31 = triton_helpers.maximum(tmp29, tmp30)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         tmp32 = tmp31.to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         tmp33 = 127.0
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         tmp34 = tmp32 / tmp33
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         tmp35 = tmp28 / tmp34
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         tmp36 = libdevice.nearbyint(tmp35)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         tmp37 = tmp36.to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         tmp38 = -127.0
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         tmp39 = triton_helpers.maximum(tmp37, tmp38)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         tmp40 = triton_helpers.minimum(tmp39, tmp33)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         tmp41 = tmp40.to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         tmp42 = tmp41.to(tl.int8)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         tl.store(out_ptr3 + (r1 + (3072*x0)), tmp42, rmask & xmask)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] ''', device_str='cuda')
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] # kernel path: /tmp/torchinductor_cpuhrsch/5n/c5n3qomkarqjnzrxppq7xsigw7vyyggezo5d3iyhioxk5hdrtpnc.py
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] # Source Nodes: [l__self___encoder_layers_encoder_layer_0_mlp_3], Original ATen: [aten._int_mm]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] # l__self___encoder_layers_encoder_layer_0_mlp_3 => _int_mm_2
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] triton_tem_fused__int_mm_7 = async_compile.triton('triton_', '''
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] import triton
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] import triton.language as tl
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor import triton_helpers, triton_heuristics
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.ir import ReductionHint, TileHint
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.triton_helpers import libdevice, math as tl_math
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.triton_heuristics import AutotuneHint
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.utils import instance_descriptor
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] @triton_heuristics.template(
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     num_stages=5,
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     num_warps=8,
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     triton_meta={'signature': {0: '*i8', 1: '*i8', 2: '*i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), divisible_by_8=())]},
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     inductor_meta={'kernel_name': 'triton_tem_fused__int_mm_7', 'backend_hash': '3259a14c125f5ba3dada77d918425e716ee1128895f1ea33af731e8e188c796e'},
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] )
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] @triton.jit
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] def triton_(arg_A, arg_B, out_ptr0):
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     GROUP_M : tl.constexpr = 8
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     EVEN_K : tl.constexpr = True
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     ALLOW_TF32 : tl.constexpr = False
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     ACC_TYPE : tl.constexpr = tl.int32
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     B_PROLOGUE_CAST_TYPE : tl.constexpr = None
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     BLOCK_M : tl.constexpr = 64
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     BLOCK_N : tl.constexpr = 32
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     BLOCK_K : tl.constexpr = 32
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     A = arg_A
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     B = arg_B
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     M = 197
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     N = 768
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     K = 3072
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     if M * N == 0:
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # early exit due to zero-size input(s)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         return
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     stride_am = 3072
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     stride_ak = 1
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     stride_bk = 1
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     stride_bn = 3072
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     # based on triton.ops.matmul
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     pid = tl.program_id(0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     grid_m = (M + BLOCK_M - 1) // BLOCK_M
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     grid_n = (N + BLOCK_N - 1) // BLOCK_N
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     # re-order program ID for better L2 performance
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     width = GROUP_M * grid_n
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     group_id = pid // width
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     group_size = min(grid_m - group_id * GROUP_M, GROUP_M)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     pid_m = group_id * GROUP_M + (pid % group_size)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     pid_n = (pid % width) // (group_size)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     rm = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     rn = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     ram = tl.max_contiguous(tl.multiple_of(rm % M, BLOCK_M), BLOCK_M)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     rbn = tl.max_contiguous(tl.multiple_of(rn % N, BLOCK_N), BLOCK_N)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     rk = tl.arange(0, BLOCK_K)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     A = A + (ram[:, None] * stride_am + rk[None, :] * stride_ak)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     B = B + (rk[:, None] * stride_bk + rbn[None, :] * stride_bn)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=ACC_TYPE)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     for k in range(K, 0, -BLOCK_K):
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         if EVEN_K:
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]             a = tl.load(A)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]             b = tl.load(B)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         else:
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]             a = tl.load(A, mask=rk[None, :] < k, other=0.)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]             b = tl.load(B, mask=rk[:, None] < k, other=0.)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         if B_PROLOGUE_CAST_TYPE is not None:
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]             b = b.to(B_PROLOGUE_CAST_TYPE)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         acc += tl.dot(a, b, allow_tf32=ALLOW_TF32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         A += BLOCK_K * stride_ak
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         B += BLOCK_K * stride_bk
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     # rematerialize rm and rn to save registers
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     rm = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     rn = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     idx_m = rm[:, None]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     idx_n = rn[None, :]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     mask = (idx_m < M) & (idx_n < N)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     # inductor generates a suffix
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     xindex = idx_n + (768*idx_m)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tl.store(out_ptr0 + (tl.broadcast_to(xindex, mask.shape)), acc, mask)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] ''', device_str='cuda')
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] meta1 = {'GROUP_M': 8, 'EVEN_K': True, 'ALLOW_TF32': False, 'ACC_TYPE': 'tl.int32', 'B_PROLOGUE_CAST_TYPE': None, 'BLOCK_M': 64, 'BLOCK_N': 32, 'BLOCK_K': 32}
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] # kernel path: /tmp/torchinductor_cpuhrsch/uo/cuonabtiiumbwnrdyj6wcrcacztynvnj4rxod3duqnxbr4ngyg4x.py
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] # Source Nodes: [add_2, x_9], Original ATen: [aten.add, aten.native_layer_norm]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] # add_2 => add_10
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] # x_9 => add_11, add_12, convert_element_type_24, convert_element_type_25, mul_13, mul_14, rsqrt_2, sub_2, var_mean_2
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] triton_per_fused_add_native_layer_norm_8 = async_compile.triton('triton_', '''
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] import triton
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] import triton.language as tl
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor import triton_helpers, triton_heuristics
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.ir import ReductionHint, TileHint
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.triton_helpers import libdevice, math as tl_math
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.triton_heuristics import AutotuneHint
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.utils import instance_descriptor
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] @triton_heuristics.persistent_reduction(
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     size_hints=[256, 1024],
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     filename=__file__,
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     triton_meta={'signature': {0: '*fp32', 1: '*bf16', 2: '*i32', 3: '*bf16', 4: '*bf16', 5: '*bf16', 6: '*bf16', 7: '*bf16', 8: '*bf16', 9: '*fp32', 10: '*bf16', 11: 'i32', 12: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12), equal_to_1=(), divisible_by_8=(12,))]},
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused_add_native_layer_norm_8', 'mutated_arg_names': ['in_out_ptr0'], 'no_x_dim': True, 'backend_hash': '3259a14c125f5ba3dada77d918425e716ee1128895f1ea33af731e8e188c796e'}
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] )
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] @triton.jit
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel):
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     xnumel = 197
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     XBLOCK: tl.constexpr = 1
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     rnumel = 768
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     RBLOCK: tl.constexpr = 1024
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     xindex = tl.full([1], xoffset, tl.int32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     xmask = xindex < xnumel
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     rindex = tl.arange(0, RBLOCK)[:]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     roffset = 0
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     rmask = rindex < rnumel
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     r1 = rindex
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     x0 = xindex
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (r1 + (768*x0)), rmask & xmask, other=0.0).to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (r1 + (768*x0)), rmask & xmask, other=0.0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp3 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last').to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp11 = tl.load(in_ptr3 + (r1), rmask, eviction_policy='evict_last', other=0.0).to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp13 = tl.load(in_ptr4 + (r1), rmask, eviction_policy='evict_last', other=0.0).to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp40 = tl.load(in_ptr5 + (r1), rmask, eviction_policy='evict_last', other=0.0).to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp43 = tl.load(in_ptr6 + (r1), rmask, eviction_policy='evict_last', other=0.0).to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp2 = tmp1.to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp4 = tmp3.to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp5 = 1e-05
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp6 = triton_helpers.maximum(tmp4, tmp5)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp7 = tmp6.to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp8 = 127.0
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp9 = tmp7 / tmp8
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp10 = tmp2 * tmp9
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp12 = tmp10 * tmp11
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp14 = tmp12 + tmp13
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp15 = tmp0 + tmp14
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp16 = tmp15.to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp17 = tl.broadcast_to(tmp16, [RBLOCK])
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp19 = tl.where(rmask & xmask, tmp17, 0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp20 = tl.broadcast_to(tmp17, [RBLOCK])
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp22 = tl.where(rmask & xmask, tmp20, 0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp23 = triton_helpers.promote_to_tensor(tl.sum(tmp22, 0))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp24 = tl.full([1], 768, tl.int32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp25 = tmp24.to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp26 = tmp23 / tmp25
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp27 = tmp17 - tmp26
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp28 = tmp27 * tmp27
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp29 = tl.broadcast_to(tmp28, [RBLOCK])
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp31 = tl.where(rmask & xmask, tmp29, 0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp32 = triton_helpers.promote_to_tensor(tl.sum(tmp31, 0))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp33 = 768.0
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp34 = tmp32 / tmp33
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp35 = 1e-06
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp36 = tmp34 + tmp35
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp37 = libdevice.rsqrt(tmp36)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp38 = tmp16 - tmp26
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp39 = tmp38 * tmp37
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp41 = tmp40.to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp42 = tmp39 * tmp41
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp44 = tmp43.to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp45 = tmp42 + tmp44
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp46 = tmp45.to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tl.store(out_ptr0 + (r1 + (768*x0)), tmp15, rmask & xmask)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tl.debug_barrier()
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tl.store(in_out_ptr0 + (x0), tmp37, xmask)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tl.store(out_ptr2 + (r1 + (768*x0)), tmp46, rmask & xmask)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tl.store(out_ptr1 + (x0), tmp26, xmask)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] ''', device_str='cuda')
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] # kernel path: /tmp/torchinductor_cpuhrsch/7y/c7y57jvybmfg2ksumvlslu47cf2gla6gphldp5iq7awqet3hp634.py
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] # Source Nodes: [x_55], Original ATen: [aten._to_copy, aten.abs, aten.amax, aten.clamp, aten.div, aten.round]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] # x_55 => abs_37, amax_36, clamp_max_36, clamp_min_72, clamp_min_73, convert_element_type_290, convert_element_type_291, convert_element_type_292, convert_element_type_293, convert_element_type_294, div_72, div_73, round_37
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] triton_per_fused__to_copy_abs_amax_clamp_div_round_9 = async_compile.triton('triton_', '''
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] import triton
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] import triton.language as tl
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor import triton_helpers, triton_heuristics
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.ir import ReductionHint, TileHint
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.triton_helpers import libdevice, math as tl_math
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.triton_heuristics import AutotuneHint
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.utils import instance_descriptor
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] @triton_heuristics.persistent_reduction(
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     size_hints=[1, 1024],
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     reduction_hint=ReductionHint.INNER,
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     filename=__file__,
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     triton_meta={'signature': {0: '*bf16', 1: '*bf16', 2: '*i8', 3: 'i32', 4: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {3: 1}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 4), equal_to_1=(3,), divisible_by_8=(4,))]},
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_per_fused__to_copy_abs_amax_clamp_div_round_9', 'mutated_arg_names': [], 'no_x_dim': True, 'backend_hash': '3259a14c125f5ba3dada77d918425e716ee1128895f1ea33af731e8e188c796e'}
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] )
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] @triton.jit
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] def triton_(in_ptr0, out_ptr0, out_ptr1, xnumel, rnumel):
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     xnumel = 1
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     XBLOCK: tl.constexpr = 1
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     rnumel = 768
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     RBLOCK: tl.constexpr = 1024
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     xindex = tl.full([1], xoffset, tl.int32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     xmask = xindex < xnumel
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     rindex = tl.arange(0, RBLOCK)[:]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     roffset = 0
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     rmask = rindex < rnumel
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     r0 = rindex
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (r0), rmask, other=0.0).to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp1 = tl_math.abs(tmp0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp2 = tl.broadcast_to(tmp1, [RBLOCK])
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp4 = tl.where(rmask, tmp2, float("-inf"))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp5 = triton_helpers.promote_to_tensor(triton_helpers.max2(tmp4, 0))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp6 = tmp5.to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp7 = 1e-05
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp8 = triton_helpers.maximum(tmp6, tmp7)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp9 = tmp8.to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp10 = 127.0
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp11 = tmp9 / tmp10
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp12 = tmp0 / tmp11
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp13 = libdevice.nearbyint(tmp12)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp14 = tmp13.to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp15 = -127.0
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp16 = triton_helpers.maximum(tmp14, tmp15)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp17 = triton_helpers.minimum(tmp16, tmp10)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp18 = tmp17.to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp19 = tmp18.to(tl.int8)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tl.store(out_ptr1 + (tl.broadcast_to(r0, [RBLOCK])), tmp19, rmask)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tl.store(out_ptr0 + (tl.full([1], 0, tl.int32)), tmp5, None)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] ''', device_str='cuda')
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] # kernel path: /tmp/torchinductor_cpuhrsch/ib/cibozvii6lvs5or6m5jocmwcjwtpegxyoxq4jk5qqid2vjvljoeb.py
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] # Source Nodes: [x_55], Original ATen: [aten._int_mm, aten._to_copy, aten.add, aten.clamp, aten.div, aten.mul, aten.round, aten.view]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] # x_55 => _int_mm_36, add_123, clamp_max_36, clamp_min_72, clamp_min_73, convert_element_type_290, convert_element_type_291, convert_element_type_292, convert_element_type_293, convert_element_type_294, div_72, div_73, mul_158, mul_159, round_37, view_361, view_362
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] triton_tem_fused__int_mm__to_copy_add_clamp_div_mul_round_view_10 = async_compile.triton('triton_', '''
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] import triton
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] import triton.language as tl
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor import triton_helpers, triton_heuristics
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.ir import ReductionHint, TileHint
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.triton_helpers import libdevice, math as tl_math
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.triton_heuristics import AutotuneHint
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] from torch._inductor.utils import instance_descriptor
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] @triton_heuristics.template(
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     num_stages=5,
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     num_warps=2,
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     triton_meta={'signature': {0: '*i8', 1: '*i8', 2: '*bf16', 3: '*bf16', 4: '*bf16', 5: '*i32', 6: '*bf16'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), divisible_by_8=())]},
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     inductor_meta={'kernel_name': 'triton_tem_fused__int_mm__to_copy_add_clamp_div_mul_round_view_10', 'backend_hash': '3259a14c125f5ba3dada77d918425e716ee1128895f1ea33af731e8e188c796e'},
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] )
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] @triton.jit
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] def triton_(arg_A, arg_B, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1):
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     GROUP_M : tl.constexpr = 8
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     EVEN_K : tl.constexpr = True
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     ALLOW_TF32 : tl.constexpr = False
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     ACC_TYPE : tl.constexpr = tl.int32
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     B_PROLOGUE_CAST_TYPE : tl.constexpr = None
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     BLOCK_M : tl.constexpr = 16
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     BLOCK_N : tl.constexpr = 32
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     BLOCK_K : tl.constexpr = 32
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     A = arg_A
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     B = arg_B
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     M = 1
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     N = 1000
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     K = 768
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     if M * N == 0:
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # early exit due to zero-size input(s)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         return
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     stride_am = 768
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     stride_ak = 1
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     stride_bk = 1
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     stride_bn = 768
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     # based on triton.ops.matmul
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     pid = tl.program_id(0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     grid_m = (M + BLOCK_M - 1) // BLOCK_M
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     grid_n = (N + BLOCK_N - 1) // BLOCK_N
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     # re-order program ID for better L2 performance
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     width = GROUP_M * grid_n
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     group_id = pid // width
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     group_size = min(grid_m - group_id * GROUP_M, GROUP_M)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     pid_m = group_id * GROUP_M + (pid % group_size)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     pid_n = (pid % width) // (group_size)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     rm = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     rn = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     ram = tl.max_contiguous(tl.multiple_of(rm % M, BLOCK_M), BLOCK_M)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     rbn = tl.max_contiguous(tl.multiple_of(rn % N, BLOCK_N), BLOCK_N)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     rk = tl.arange(0, BLOCK_K)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     A = A + (ram[:, None] * stride_am + rk[None, :] * stride_ak)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     B = B + (rk[:, None] * stride_bk + rbn[None, :] * stride_bn)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=ACC_TYPE)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     for k in range(K, 0, -BLOCK_K):
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         if EVEN_K:
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]             a = tl.load(A)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]             b = tl.load(B)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         else:
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]             a = tl.load(A, mask=rk[None, :] < k, other=0.)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]             b = tl.load(B, mask=rk[:, None] < k, other=0.)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         if B_PROLOGUE_CAST_TYPE is not None:
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]             b = b.to(B_PROLOGUE_CAST_TYPE)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         acc += tl.dot(a, b, allow_tf32=ALLOW_TF32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         A += BLOCK_K * stride_ak
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         B += BLOCK_K * stride_bk
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     # rematerialize rm and rn to save registers
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     rm = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     rn = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     idx_m = rm[:, None]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     idx_n = rn[None, :]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     mask = (idx_m < M) & (idx_n < N)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     # inductor generates a suffix
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     xindex = idx_n + (1000*idx_m)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tl.store(out_ptr0 + (tl.broadcast_to(idx_n, mask.shape)), acc, mask)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp1 = tl.load(in_ptr2 + (0)).to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp2 = tl.broadcast_to(tmp1, mask.shape)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp10 = tl.load(in_ptr3 + (tl.broadcast_to(xindex, mask.shape)), mask, eviction_policy='evict_last').to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp12 = tl.load(in_ptr4 + (tl.broadcast_to(xindex, mask.shape)), mask, eviction_policy='evict_last').to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp0 = acc.to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp3 = tmp2.to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp4 = 1e-05
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp5 = triton_helpers.maximum(tmp3, tmp4)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp6 = tmp5.to(tl.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp7 = 127.0
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp8 = tmp6 / tmp7
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp9 = tmp0 * tmp8
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp11 = tmp9 * tmp10
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tmp13 = tmp11 + tmp12
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     tl.store(out_ptr1 + (tl.broadcast_to(xindex, mask.shape)), tmp13, mask)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] ''', device_str='cuda')
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] meta2 = {'GROUP_M': 8, 'EVEN_K': True, 'ALLOW_TF32': False, 'ACC_TYPE': 'tl.int32', 'B_PROLOGUE_CAST_TYPE': None, 'BLOCK_M': 16, 'BLOCK_N': 32, 'BLOCK_K': 32}
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] async_compile.wait(globals())
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] del async_compile
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] def call(args):
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42, primals_43, primals_44, primals_45, primals_46, primals_47, primals_48, primals_49, primals_50, primals_51, primals_52, primals_53, primals_54, primals_55, primals_56, primals_57, primals_58, primals_59, primals_60, primals_61, primals_62, primals_63, primals_64, primals_65, primals_66, primals_67, primals_68, primals_69, primals_70, primals_71, primals_72, primals_73, primals_74, primals_75, primals_76, primals_77, primals_78, primals_79, primals_80, primals_81, primals_82, primals_83, primals_84, primals_85, primals_86, primals_87, primals_88, primals_89, primals_90, primals_91, primals_92, primals_93, primals_94, primals_95, primals_96, primals_97, primals_98, primals_99, primals_100, primals_101, primals_102, primals_103, primals_104, primals_105, primals_106, primals_107, primals_108, primals_109, primals_110, primals_111, primals_112, primals_113, primals_114, primals_115, primals_116, primals_117, primals_118, primals_119, primals_120, primals_121, primals_122, primals_123, primals_124, primals_125, primals_126, primals_127, primals_128, primals_129, primals_130, primals_131, primals_132, primals_133, primals_134, primals_135, primals_136, primals_137, primals_138, primals_139, primals_140, primals_141, primals_142, primals_143, primals_144, primals_145, primals_146, primals_147, primals_148, primals_149, primals_150, primals_151, primals_152, primals_153, primals_154, primals_155, primals_156, primals_157, primals_158, primals_159, primals_160, primals_161, primals_162, primals_163, primals_164, primals_165, primals_166, primals_167, primals_168, primals_169, primals_170, primals_171, primals_172, primals_173, primals_174, primals_175, primals_176, primals_177, primals_178, primals_179, primals_180, primals_181, primals_182, primals_183, primals_184, primals_185, primals_186, primals_187, primals_188, primals_189, primals_190 = args
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     args.clear()
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_1, (1, 1, 768), (768, 768, 1))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_2, (1, 197, 768), (151296, 768, 1))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_3, (768, 3, 16, 16), (768, 256, 16, 1))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_4, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_5, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_6, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_7, (2304, 768), (768, 1))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_8, (2304, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_9, (768, 768), (1, 768))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_10, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_11, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_12, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_13, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_14, (768, 3072), (1, 768))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_15, (3072, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_16, (3072, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_17, (3072, 768), (1, 3072))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_18, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_19, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_20, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_21, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_22, (2304, 768), (768, 1))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_23, (2304, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_24, (768, 768), (1, 768))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_25, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_26, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_27, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_28, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_29, (768, 3072), (1, 768))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_30, (3072, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_31, (3072, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_32, (3072, 768), (1, 3072))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_33, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_34, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_35, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_36, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_37, (2304, 768), (768, 1))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_38, (2304, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_39, (768, 768), (1, 768))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_40, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_41, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_42, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_43, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_44, (768, 3072), (1, 768))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_45, (3072, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_46, (3072, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_47, (3072, 768), (1, 3072))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_48, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_49, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_50, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_51, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_52, (2304, 768), (768, 1))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_53, (2304, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_54, (768, 768), (1, 768))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_55, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_56, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_57, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_58, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_59, (768, 3072), (1, 768))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_60, (3072, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_61, (3072, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_62, (3072, 768), (1, 3072))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_63, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_64, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_65, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_66, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_67, (2304, 768), (768, 1))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_68, (2304, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_69, (768, 768), (1, 768))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_70, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_71, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_72, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_73, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_74, (768, 3072), (1, 768))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_75, (3072, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_76, (3072, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_77, (3072, 768), (1, 3072))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_78, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_79, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_80, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_81, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_82, (2304, 768), (768, 1))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_83, (2304, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_84, (768, 768), (1, 768))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_85, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_86, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_87, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_88, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_89, (768, 3072), (1, 768))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_90, (3072, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_91, (3072, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_92, (3072, 768), (1, 3072))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_93, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_94, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_95, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_96, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_97, (2304, 768), (768, 1))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_98, (2304, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_99, (768, 768), (1, 768))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_100, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_101, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_102, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_103, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_104, (768, 3072), (1, 768))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_105, (3072, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_106, (3072, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_107, (3072, 768), (1, 3072))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_108, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_109, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_110, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_111, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_112, (2304, 768), (768, 1))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_113, (2304, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_114, (768, 768), (1, 768))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_115, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_116, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_117, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_118, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_119, (768, 3072), (1, 768))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_120, (3072, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_121, (3072, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_122, (3072, 768), (1, 3072))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_123, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_124, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_125, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_126, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_127, (2304, 768), (768, 1))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_128, (2304, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_129, (768, 768), (1, 768))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_130, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_131, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_132, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_133, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_134, (768, 3072), (1, 768))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_135, (3072, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_136, (3072, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_137, (3072, 768), (1, 3072))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_138, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_139, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_140, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_141, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_142, (2304, 768), (768, 1))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_143, (2304, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_144, (768, 768), (1, 768))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_145, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_146, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_147, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_148, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_149, (768, 3072), (1, 768))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_150, (3072, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_151, (3072, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_152, (3072, 768), (1, 3072))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_153, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_154, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_155, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_156, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_157, (2304, 768), (768, 1))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_158, (2304, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_159, (768, 768), (1, 768))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_160, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_161, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_162, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_163, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_164, (768, 3072), (1, 768))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_165, (3072, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_166, (3072, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_167, (3072, 768), (1, 3072))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_168, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_169, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_170, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_171, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_172, (2304, 768), (768, 1))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_173, (2304, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_174, (768, 768), (1, 768))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_175, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_176, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_177, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_178, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_179, (768, 3072), (1, 768))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_180, (3072, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_181, (3072, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_182, (3072, 768), (1, 3072))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_183, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_184, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_185, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_186, (768, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_187, (768, 1000), (1, 768))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_188, (1000, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_189, (1000, ), (1, ))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     assert_size_stride(primals_190, (1, 3, 224, 224), (150528, 50176, 224, 1))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     with torch.cuda._DeviceGuard(0):
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         torch.cuda.set_device(0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [x], Original ATen: [aten.convolution]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf0 = extern_kernels.convolution(primals_190, primals_3, stride=(16, 16), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         assert_size_stride(buf0, (1, 768, 14, 14), (150528, 196, 14, 1))
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf1 = empty_strided_cuda((1, 197, 768), (151296, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf2 = empty_strided_cuda((1, 197, 1), (197, 1, 1), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf3 = empty_strided_cuda((1, 197, 1), (197, 1, 197), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf5 = reinterpret_tensor(buf3, (1, 197, 1), (197, 1, 1), 0); del buf3  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf6 = empty_strided_cuda((1, 197, 768), (151296, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [cat_1, input_1, x_5], Original ATen: [aten.add, aten.cat, aten.native_layer_norm]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_per_fused_add_cat_native_layer_norm_0.run(buf5, primals_1, buf0, primals_4, primals_2, primals_5, primals_6, buf1, buf2, buf6, 197, 768, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del buf0
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_1
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_2
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_4
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_6
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf7 = empty_strided_cuda((197, 2304), (2304, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [], Original ATen: []
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf6, (197, 768), (768, 1), 0), reinterpret_tensor(primals_7, (768, 2304), (1, 768), 0), out=buf7)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf8 = empty_strided_cuda((3, 197, 1, 768), (151296, 768, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_0_self_attention], Original ATen: [aten.clone]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_poi_fused_clone_1.run(buf7, primals_8, buf8, 453888, grid=grid(453888), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_8
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_0_self_attention], Original ATen: [aten._scaled_dot_product_flash_attention]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf9 = aten._scaled_dot_product_flash_attention.default(reinterpret_tensor(buf8, (1, 12, 197, 64), (0, 64, 768, 1), 0), reinterpret_tensor(buf8, (1, 12, 197, 64), (0, 64, 768, 1), 151296), reinterpret_tensor(buf8, (1, 12, 197, 64), (0, 64, 768, 1), 302592), scale=0.125)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf10 = buf9[0]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf11 = buf9[1]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf12 = buf9[6]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf13 = buf9[7]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del buf9
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf16 = empty_strided_cuda((197, 768), (768, 1), torch.int8)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf17 = empty_strided_cuda((197, 1), (1, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_0_self_attention], Original ATen: [aten._to_copy, aten.abs, aten.amax, aten.clamp, aten.div, aten.round]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_per_fused__to_copy_abs_amax_clamp_div_round_2.run(buf10, buf16, buf17, 197, 768, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf18 = empty_strided_cuda((197, 768), (768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_0_self_attention], Original ATen: [aten._to_copy, aten.clamp, aten.div, aten.mul, aten.round, aten.view]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_tem_fused__to_copy_clamp_div_mul_round_view_3.run(buf16, primals_9, buf17, buf18, grid=torch._inductor.kernel.mm_common.mm_grid(197, 768, meta0), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf19 = reinterpret_tensor(buf18, (1, 197, 768), (151296, 768, 1), 0); del buf18  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf20 = empty_strided_cuda((1, 197, 1), (197, 1, 1), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf21 = empty_strided_cuda((1, 197, 1), (197, 1, 197), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf23 = reinterpret_tensor(buf21, (1, 197, 1), (197, 1, 1), 0); del buf21  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf24 = empty_strided_cuda((1, 197, 768), (151296, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf25 = reinterpret_tensor(buf17, (1, 197, 1), (197, 1, 1), 0); del buf17  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf26 = reinterpret_tensor(buf16, (1, 197, 768), (151296, 768, 1), 0); del buf16  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_0_mlp_0, x_7, x_8, y], Original ATen: [aten._to_copy, aten.abs, aten.add, aten.amax, aten.clamp, aten.clone, aten.div, aten.native_layer_norm, aten.round]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_per_fused__to_copy_abs_add_amax_clamp_clone_div_native_layer_norm_round_4.run(buf19, buf23, primals_10, primals_11, buf1, primals_12, primals_13, buf20, buf24, buf25, buf26, 197, 768, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_11
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_13
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf27 = empty_strided_cuda((197, 3072), (3072, 1), torch.int32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_0_mlp_0], Original ATen: [aten._int_mm]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_tem_fused__int_mm_5.run(buf26, primals_14, buf27, grid=torch._inductor.kernel.mm_common.mm_grid(197, 3072, meta0), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_14
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf28 = empty_strided_cuda((1, 197, 3072), (605184, 3072, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf29 = empty_strided_cuda((1, 197, 3072), (605184, 3072, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf30 = empty_strided_cuda((1, 197, 1), (197, 1, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf31 = empty_strided_cuda((1, 197, 3072), (605184, 3072, 1), torch.int8)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_0_mlp_0, l__self___encoder_layers_encoder_layer_0_mlp_1, l__self___encoder_layers_encoder_layer_0_mlp_3], Original ATen: [aten._to_copy, aten.abs, aten.add, aten.amax, aten.clamp, aten.div, aten.gelu, aten.round]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_red_fused__to_copy_abs_add_amax_clamp_div_gelu_round_6.run(buf27, buf25, primals_15, primals_16, buf28, buf29, buf30, buf31, 197, 3072, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_16
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf32 = empty_strided_cuda((197, 768), (768, 1), torch.int32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_0_mlp_3], Original ATen: [aten._int_mm]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_tem_fused__int_mm_7.run(buf31, primals_17, buf32, grid=torch._inductor.kernel.mm_common.mm_grid(197, 768, meta1), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_17
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf33 = empty_strided_cuda((1, 197, 768), (151296, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf34 = empty_strided_cuda((1, 197, 1), (197, 1, 1), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf35 = empty_strided_cuda((1, 197, 1), (197, 1, 197), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf37 = reinterpret_tensor(buf35, (1, 197, 1), (197, 1, 1), 0); del buf35  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf38 = empty_strided_cuda((1, 197, 768), (151296, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [add_2, x_9], Original ATen: [aten.add, aten.native_layer_norm]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_per_fused_add_native_layer_norm_8.run(buf37, buf19, buf32, buf30, primals_18, primals_19, primals_20, primals_21, buf33, buf34, buf38, 197, 768, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_19
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_21
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf39 = buf7; del buf7  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [], Original ATen: []
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf38, (197, 768), (768, 1), 0), reinterpret_tensor(primals_22, (768, 2304), (1, 768), 0), out=buf39)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf40 = empty_strided_cuda((3, 197, 1, 768), (151296, 768, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_1_self_attention], Original ATen: [aten.clone]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_poi_fused_clone_1.run(buf39, primals_23, buf40, 453888, grid=grid(453888), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_23
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_1_self_attention], Original ATen: [aten._scaled_dot_product_flash_attention]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf41 = aten._scaled_dot_product_flash_attention.default(reinterpret_tensor(buf40, (1, 12, 197, 64), (0, 64, 768, 1), 0), reinterpret_tensor(buf40, (1, 12, 197, 64), (0, 64, 768, 1), 151296), reinterpret_tensor(buf40, (1, 12, 197, 64), (0, 64, 768, 1), 302592), scale=0.125)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf42 = buf41[0]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf43 = buf41[1]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf44 = buf41[6]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf45 = buf41[7]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del buf41
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf48 = reinterpret_tensor(buf26, (197, 768), (768, 1), 0); del buf26  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf49 = empty_strided_cuda((197, 1), (1, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_1_self_attention], Original ATen: [aten._to_copy, aten.abs, aten.amax, aten.clamp, aten.div, aten.round]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_per_fused__to_copy_abs_amax_clamp_div_round_2.run(buf42, buf48, buf49, 197, 768, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf50 = empty_strided_cuda((197, 768), (768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_1_self_attention], Original ATen: [aten._to_copy, aten.clamp, aten.div, aten.mul, aten.round, aten.view]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_tem_fused__to_copy_clamp_div_mul_round_view_3.run(buf48, primals_24, buf49, buf50, grid=torch._inductor.kernel.mm_common.mm_grid(197, 768, meta0), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf51 = reinterpret_tensor(buf50, (1, 197, 768), (151296, 768, 1), 0); del buf50  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf52 = empty_strided_cuda((1, 197, 1), (197, 1, 1), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf53 = empty_strided_cuda((1, 197, 1), (197, 1, 197), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf55 = reinterpret_tensor(buf53, (1, 197, 1), (197, 1, 1), 0); del buf53  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf56 = empty_strided_cuda((1, 197, 768), (151296, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf57 = reinterpret_tensor(buf49, (1, 197, 1), (197, 1, 1), 0); del buf49  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf58 = reinterpret_tensor(buf48, (1, 197, 768), (151296, 768, 1), 0); del buf48  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_1_mlp_0, x_11, x_12, y_2], Original ATen: [aten._to_copy, aten.abs, aten.add, aten.amax, aten.clamp, aten.clone, aten.div, aten.native_layer_norm, aten.round]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_per_fused__to_copy_abs_add_amax_clamp_clone_div_native_layer_norm_round_4.run(buf51, buf55, primals_25, primals_26, buf33, primals_27, primals_28, buf52, buf56, buf57, buf58, 197, 768, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_26
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_28
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf59 = empty_strided_cuda((197, 3072), (3072, 1), torch.int32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_1_mlp_0], Original ATen: [aten._int_mm]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_tem_fused__int_mm_5.run(buf58, primals_29, buf59, grid=torch._inductor.kernel.mm_common.mm_grid(197, 3072, meta0), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_29
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf60 = empty_strided_cuda((1, 197, 3072), (605184, 3072, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf61 = empty_strided_cuda((1, 197, 3072), (605184, 3072, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf62 = empty_strided_cuda((1, 197, 1), (197, 1, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf63 = buf31; del buf31  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_1_mlp_0, l__self___encoder_layers_encoder_layer_1_mlp_1, l__self___encoder_layers_encoder_layer_1_mlp_3], Original ATen: [aten._to_copy, aten.abs, aten.add, aten.amax, aten.clamp, aten.div, aten.gelu, aten.round]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_red_fused__to_copy_abs_add_amax_clamp_div_gelu_round_6.run(buf59, buf57, primals_30, primals_31, buf60, buf61, buf62, buf63, 197, 3072, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_31
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf64 = empty_strided_cuda((197, 768), (768, 1), torch.int32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_1_mlp_3], Original ATen: [aten._int_mm]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_tem_fused__int_mm_7.run(buf63, primals_32, buf64, grid=torch._inductor.kernel.mm_common.mm_grid(197, 768, meta1), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_32
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf65 = empty_strided_cuda((1, 197, 768), (151296, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf66 = empty_strided_cuda((1, 197, 1), (197, 1, 1), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf67 = empty_strided_cuda((1, 197, 1), (197, 1, 197), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf69 = reinterpret_tensor(buf67, (1, 197, 1), (197, 1, 1), 0); del buf67  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf70 = empty_strided_cuda((1, 197, 768), (151296, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [add_4, x_13], Original ATen: [aten.add, aten.native_layer_norm]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_per_fused_add_native_layer_norm_8.run(buf69, buf51, buf64, buf62, primals_33, primals_34, primals_35, primals_36, buf65, buf66, buf70, 197, 768, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_34
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_36
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf71 = buf39; del buf39  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [], Original ATen: []
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf70, (197, 768), (768, 1), 0), reinterpret_tensor(primals_37, (768, 2304), (1, 768), 0), out=buf71)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf72 = empty_strided_cuda((3, 197, 1, 768), (151296, 768, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_2_self_attention], Original ATen: [aten.clone]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_poi_fused_clone_1.run(buf71, primals_38, buf72, 453888, grid=grid(453888), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_38
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_2_self_attention], Original ATen: [aten._scaled_dot_product_flash_attention]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf73 = aten._scaled_dot_product_flash_attention.default(reinterpret_tensor(buf72, (1, 12, 197, 64), (0, 64, 768, 1), 0), reinterpret_tensor(buf72, (1, 12, 197, 64), (0, 64, 768, 1), 151296), reinterpret_tensor(buf72, (1, 12, 197, 64), (0, 64, 768, 1), 302592), scale=0.125)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf74 = buf73[0]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf75 = buf73[1]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf76 = buf73[6]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf77 = buf73[7]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del buf73
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf80 = reinterpret_tensor(buf58, (197, 768), (768, 1), 0); del buf58  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf81 = empty_strided_cuda((197, 1), (1, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_2_self_attention], Original ATen: [aten._to_copy, aten.abs, aten.amax, aten.clamp, aten.div, aten.round]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_per_fused__to_copy_abs_amax_clamp_div_round_2.run(buf74, buf80, buf81, 197, 768, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf82 = empty_strided_cuda((197, 768), (768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_2_self_attention], Original ATen: [aten._to_copy, aten.clamp, aten.div, aten.mul, aten.round, aten.view]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_tem_fused__to_copy_clamp_div_mul_round_view_3.run(buf80, primals_39, buf81, buf82, grid=torch._inductor.kernel.mm_common.mm_grid(197, 768, meta0), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf83 = reinterpret_tensor(buf82, (1, 197, 768), (151296, 768, 1), 0); del buf82  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf84 = empty_strided_cuda((1, 197, 1), (197, 1, 1), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf85 = empty_strided_cuda((1, 197, 1), (197, 1, 197), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf87 = reinterpret_tensor(buf85, (1, 197, 1), (197, 1, 1), 0); del buf85  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf88 = empty_strided_cuda((1, 197, 768), (151296, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf89 = reinterpret_tensor(buf81, (1, 197, 1), (197, 1, 1), 0); del buf81  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf90 = reinterpret_tensor(buf80, (1, 197, 768), (151296, 768, 1), 0); del buf80  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_2_mlp_0, x_15, x_16, y_4], Original ATen: [aten._to_copy, aten.abs, aten.add, aten.amax, aten.clamp, aten.clone, aten.div, aten.native_layer_norm, aten.round]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_per_fused__to_copy_abs_add_amax_clamp_clone_div_native_layer_norm_round_4.run(buf83, buf87, primals_40, primals_41, buf65, primals_42, primals_43, buf84, buf88, buf89, buf90, 197, 768, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_41
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_43
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf91 = empty_strided_cuda((197, 3072), (3072, 1), torch.int32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_2_mlp_0], Original ATen: [aten._int_mm]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_tem_fused__int_mm_5.run(buf90, primals_44, buf91, grid=torch._inductor.kernel.mm_common.mm_grid(197, 3072, meta0), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_44
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf92 = empty_strided_cuda((1, 197, 3072), (605184, 3072, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf93 = empty_strided_cuda((1, 197, 3072), (605184, 3072, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf94 = empty_strided_cuda((1, 197, 1), (197, 1, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf95 = buf63; del buf63  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_2_mlp_0, l__self___encoder_layers_encoder_layer_2_mlp_1, l__self___encoder_layers_encoder_layer_2_mlp_3], Original ATen: [aten._to_copy, aten.abs, aten.add, aten.amax, aten.clamp, aten.div, aten.gelu, aten.round]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_red_fused__to_copy_abs_add_amax_clamp_div_gelu_round_6.run(buf91, buf89, primals_45, primals_46, buf92, buf93, buf94, buf95, 197, 3072, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_46
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf96 = empty_strided_cuda((197, 768), (768, 1), torch.int32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_2_mlp_3], Original ATen: [aten._int_mm]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_tem_fused__int_mm_7.run(buf95, primals_47, buf96, grid=torch._inductor.kernel.mm_common.mm_grid(197, 768, meta1), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_47
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf97 = empty_strided_cuda((1, 197, 768), (151296, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf98 = empty_strided_cuda((1, 197, 1), (197, 1, 1), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf99 = empty_strided_cuda((1, 197, 1), (197, 1, 197), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf101 = reinterpret_tensor(buf99, (1, 197, 1), (197, 1, 1), 0); del buf99  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf102 = empty_strided_cuda((1, 197, 768), (151296, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [add_6, x_17], Original ATen: [aten.add, aten.native_layer_norm]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_per_fused_add_native_layer_norm_8.run(buf101, buf83, buf96, buf94, primals_48, primals_49, primals_50, primals_51, buf97, buf98, buf102, 197, 768, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_49
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_51
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf103 = buf71; del buf71  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [], Original ATen: []
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf102, (197, 768), (768, 1), 0), reinterpret_tensor(primals_52, (768, 2304), (1, 768), 0), out=buf103)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf104 = empty_strided_cuda((3, 197, 1, 768), (151296, 768, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_3_self_attention], Original ATen: [aten.clone]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_poi_fused_clone_1.run(buf103, primals_53, buf104, 453888, grid=grid(453888), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_53
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_3_self_attention], Original ATen: [aten._scaled_dot_product_flash_attention]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf105 = aten._scaled_dot_product_flash_attention.default(reinterpret_tensor(buf104, (1, 12, 197, 64), (0, 64, 768, 1), 0), reinterpret_tensor(buf104, (1, 12, 197, 64), (0, 64, 768, 1), 151296), reinterpret_tensor(buf104, (1, 12, 197, 64), (0, 64, 768, 1), 302592), scale=0.125)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf106 = buf105[0]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf107 = buf105[1]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf108 = buf105[6]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf109 = buf105[7]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del buf105
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf112 = reinterpret_tensor(buf90, (197, 768), (768, 1), 0); del buf90  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf113 = empty_strided_cuda((197, 1), (1, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_3_self_attention], Original ATen: [aten._to_copy, aten.abs, aten.amax, aten.clamp, aten.div, aten.round]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_per_fused__to_copy_abs_amax_clamp_div_round_2.run(buf106, buf112, buf113, 197, 768, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf114 = empty_strided_cuda((197, 768), (768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_3_self_attention], Original ATen: [aten._to_copy, aten.clamp, aten.div, aten.mul, aten.round, aten.view]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_tem_fused__to_copy_clamp_div_mul_round_view_3.run(buf112, primals_54, buf113, buf114, grid=torch._inductor.kernel.mm_common.mm_grid(197, 768, meta0), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf115 = reinterpret_tensor(buf114, (1, 197, 768), (151296, 768, 1), 0); del buf114  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf116 = empty_strided_cuda((1, 197, 1), (197, 1, 1), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf117 = empty_strided_cuda((1, 197, 1), (197, 1, 197), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf119 = reinterpret_tensor(buf117, (1, 197, 1), (197, 1, 1), 0); del buf117  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf120 = empty_strided_cuda((1, 197, 768), (151296, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf121 = reinterpret_tensor(buf113, (1, 197, 1), (197, 1, 1), 0); del buf113  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf122 = reinterpret_tensor(buf112, (1, 197, 768), (151296, 768, 1), 0); del buf112  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_3_mlp_0, x_19, x_20, y_6], Original ATen: [aten._to_copy, aten.abs, aten.add, aten.amax, aten.clamp, aten.clone, aten.div, aten.native_layer_norm, aten.round]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_per_fused__to_copy_abs_add_amax_clamp_clone_div_native_layer_norm_round_4.run(buf115, buf119, primals_55, primals_56, buf97, primals_57, primals_58, buf116, buf120, buf121, buf122, 197, 768, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_56
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_58
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf123 = empty_strided_cuda((197, 3072), (3072, 1), torch.int32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_3_mlp_0], Original ATen: [aten._int_mm]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_tem_fused__int_mm_5.run(buf122, primals_59, buf123, grid=torch._inductor.kernel.mm_common.mm_grid(197, 3072, meta0), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_59
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf124 = empty_strided_cuda((1, 197, 3072), (605184, 3072, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf125 = empty_strided_cuda((1, 197, 3072), (605184, 3072, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf126 = empty_strided_cuda((1, 197, 1), (197, 1, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf127 = buf95; del buf95  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_3_mlp_0, l__self___encoder_layers_encoder_layer_3_mlp_1, l__self___encoder_layers_encoder_layer_3_mlp_3], Original ATen: [aten._to_copy, aten.abs, aten.add, aten.amax, aten.clamp, aten.div, aten.gelu, aten.round]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_red_fused__to_copy_abs_add_amax_clamp_div_gelu_round_6.run(buf123, buf121, primals_60, primals_61, buf124, buf125, buf126, buf127, 197, 3072, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_61
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf128 = empty_strided_cuda((197, 768), (768, 1), torch.int32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_3_mlp_3], Original ATen: [aten._int_mm]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_tem_fused__int_mm_7.run(buf127, primals_62, buf128, grid=torch._inductor.kernel.mm_common.mm_grid(197, 768, meta1), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_62
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf129 = empty_strided_cuda((1, 197, 768), (151296, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf130 = empty_strided_cuda((1, 197, 1), (197, 1, 1), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf131 = empty_strided_cuda((1, 197, 1), (197, 1, 197), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf133 = reinterpret_tensor(buf131, (1, 197, 1), (197, 1, 1), 0); del buf131  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf134 = empty_strided_cuda((1, 197, 768), (151296, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [add_8, x_21], Original ATen: [aten.add, aten.native_layer_norm]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_per_fused_add_native_layer_norm_8.run(buf133, buf115, buf128, buf126, primals_63, primals_64, primals_65, primals_66, buf129, buf130, buf134, 197, 768, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_64
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_66
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf135 = buf103; del buf103  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [], Original ATen: []
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf134, (197, 768), (768, 1), 0), reinterpret_tensor(primals_67, (768, 2304), (1, 768), 0), out=buf135)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf136 = empty_strided_cuda((3, 197, 1, 768), (151296, 768, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_4_self_attention], Original ATen: [aten.clone]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_poi_fused_clone_1.run(buf135, primals_68, buf136, 453888, grid=grid(453888), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_68
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_4_self_attention], Original ATen: [aten._scaled_dot_product_flash_attention]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf137 = aten._scaled_dot_product_flash_attention.default(reinterpret_tensor(buf136, (1, 12, 197, 64), (0, 64, 768, 1), 0), reinterpret_tensor(buf136, (1, 12, 197, 64), (0, 64, 768, 1), 151296), reinterpret_tensor(buf136, (1, 12, 197, 64), (0, 64, 768, 1), 302592), scale=0.125)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf138 = buf137[0]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf139 = buf137[1]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf140 = buf137[6]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf141 = buf137[7]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del buf137
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf144 = reinterpret_tensor(buf122, (197, 768), (768, 1), 0); del buf122  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf145 = empty_strided_cuda((197, 1), (1, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_4_self_attention], Original ATen: [aten._to_copy, aten.abs, aten.amax, aten.clamp, aten.div, aten.round]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_per_fused__to_copy_abs_amax_clamp_div_round_2.run(buf138, buf144, buf145, 197, 768, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf146 = empty_strided_cuda((197, 768), (768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_4_self_attention], Original ATen: [aten._to_copy, aten.clamp, aten.div, aten.mul, aten.round, aten.view]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_tem_fused__to_copy_clamp_div_mul_round_view_3.run(buf144, primals_69, buf145, buf146, grid=torch._inductor.kernel.mm_common.mm_grid(197, 768, meta0), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf147 = reinterpret_tensor(buf146, (1, 197, 768), (151296, 768, 1), 0); del buf146  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf148 = empty_strided_cuda((1, 197, 1), (197, 1, 1), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf149 = empty_strided_cuda((1, 197, 1), (197, 1, 197), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf151 = reinterpret_tensor(buf149, (1, 197, 1), (197, 1, 1), 0); del buf149  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf152 = empty_strided_cuda((1, 197, 768), (151296, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf153 = reinterpret_tensor(buf145, (1, 197, 1), (197, 1, 1), 0); del buf145  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf154 = reinterpret_tensor(buf144, (1, 197, 768), (151296, 768, 1), 0); del buf144  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_4_mlp_0, x_23, x_24, y_8], Original ATen: [aten._to_copy, aten.abs, aten.add, aten.amax, aten.clamp, aten.clone, aten.div, aten.native_layer_norm, aten.round]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_per_fused__to_copy_abs_add_amax_clamp_clone_div_native_layer_norm_round_4.run(buf147, buf151, primals_70, primals_71, buf129, primals_72, primals_73, buf148, buf152, buf153, buf154, 197, 768, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_71
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_73
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf155 = empty_strided_cuda((197, 3072), (3072, 1), torch.int32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_4_mlp_0], Original ATen: [aten._int_mm]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_tem_fused__int_mm_5.run(buf154, primals_74, buf155, grid=torch._inductor.kernel.mm_common.mm_grid(197, 3072, meta0), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_74
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf156 = empty_strided_cuda((1, 197, 3072), (605184, 3072, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf157 = empty_strided_cuda((1, 197, 3072), (605184, 3072, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf158 = empty_strided_cuda((1, 197, 1), (197, 1, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf159 = buf127; del buf127  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_4_mlp_0, l__self___encoder_layers_encoder_layer_4_mlp_1, l__self___encoder_layers_encoder_layer_4_mlp_3], Original ATen: [aten._to_copy, aten.abs, aten.add, aten.amax, aten.clamp, aten.div, aten.gelu, aten.round]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_red_fused__to_copy_abs_add_amax_clamp_div_gelu_round_6.run(buf155, buf153, primals_75, primals_76, buf156, buf157, buf158, buf159, 197, 3072, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_76
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf160 = empty_strided_cuda((197, 768), (768, 1), torch.int32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_4_mlp_3], Original ATen: [aten._int_mm]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_tem_fused__int_mm_7.run(buf159, primals_77, buf160, grid=torch._inductor.kernel.mm_common.mm_grid(197, 768, meta1), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_77
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf161 = empty_strided_cuda((1, 197, 768), (151296, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf162 = empty_strided_cuda((1, 197, 1), (197, 1, 1), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf163 = empty_strided_cuda((1, 197, 1), (197, 1, 197), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf165 = reinterpret_tensor(buf163, (1, 197, 1), (197, 1, 1), 0); del buf163  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf166 = empty_strided_cuda((1, 197, 768), (151296, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [add_10, x_25], Original ATen: [aten.add, aten.native_layer_norm]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_per_fused_add_native_layer_norm_8.run(buf165, buf147, buf160, buf158, primals_78, primals_79, primals_80, primals_81, buf161, buf162, buf166, 197, 768, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_79
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_81
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf167 = buf135; del buf135  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [], Original ATen: []
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf166, (197, 768), (768, 1), 0), reinterpret_tensor(primals_82, (768, 2304), (1, 768), 0), out=buf167)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf168 = empty_strided_cuda((3, 197, 1, 768), (151296, 768, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_5_self_attention], Original ATen: [aten.clone]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_poi_fused_clone_1.run(buf167, primals_83, buf168, 453888, grid=grid(453888), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_83
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_5_self_attention], Original ATen: [aten._scaled_dot_product_flash_attention]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf169 = aten._scaled_dot_product_flash_attention.default(reinterpret_tensor(buf168, (1, 12, 197, 64), (0, 64, 768, 1), 0), reinterpret_tensor(buf168, (1, 12, 197, 64), (0, 64, 768, 1), 151296), reinterpret_tensor(buf168, (1, 12, 197, 64), (0, 64, 768, 1), 302592), scale=0.125)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf170 = buf169[0]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf171 = buf169[1]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf172 = buf169[6]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf173 = buf169[7]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del buf169
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf176 = reinterpret_tensor(buf154, (197, 768), (768, 1), 0); del buf154  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf177 = empty_strided_cuda((197, 1), (1, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_5_self_attention], Original ATen: [aten._to_copy, aten.abs, aten.amax, aten.clamp, aten.div, aten.round]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_per_fused__to_copy_abs_amax_clamp_div_round_2.run(buf170, buf176, buf177, 197, 768, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf178 = empty_strided_cuda((197, 768), (768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_5_self_attention], Original ATen: [aten._to_copy, aten.clamp, aten.div, aten.mul, aten.round, aten.view]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_tem_fused__to_copy_clamp_div_mul_round_view_3.run(buf176, primals_84, buf177, buf178, grid=torch._inductor.kernel.mm_common.mm_grid(197, 768, meta0), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf179 = reinterpret_tensor(buf178, (1, 197, 768), (151296, 768, 1), 0); del buf178  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf180 = empty_strided_cuda((1, 197, 1), (197, 1, 1), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf181 = empty_strided_cuda((1, 197, 1), (197, 1, 197), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf183 = reinterpret_tensor(buf181, (1, 197, 1), (197, 1, 1), 0); del buf181  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf184 = empty_strided_cuda((1, 197, 768), (151296, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf185 = reinterpret_tensor(buf177, (1, 197, 1), (197, 1, 1), 0); del buf177  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf186 = reinterpret_tensor(buf176, (1, 197, 768), (151296, 768, 1), 0); del buf176  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_5_mlp_0, x_27, x_28, y_10], Original ATen: [aten._to_copy, aten.abs, aten.add, aten.amax, aten.clamp, aten.clone, aten.div, aten.native_layer_norm, aten.round]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_per_fused__to_copy_abs_add_amax_clamp_clone_div_native_layer_norm_round_4.run(buf179, buf183, primals_85, primals_86, buf161, primals_87, primals_88, buf180, buf184, buf185, buf186, 197, 768, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_86
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_88
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf187 = empty_strided_cuda((197, 3072), (3072, 1), torch.int32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_5_mlp_0], Original ATen: [aten._int_mm]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_tem_fused__int_mm_5.run(buf186, primals_89, buf187, grid=torch._inductor.kernel.mm_common.mm_grid(197, 3072, meta0), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_89
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf188 = empty_strided_cuda((1, 197, 3072), (605184, 3072, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf189 = empty_strided_cuda((1, 197, 3072), (605184, 3072, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf190 = empty_strided_cuda((1, 197, 1), (197, 1, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf191 = buf159; del buf159  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_5_mlp_0, l__self___encoder_layers_encoder_layer_5_mlp_1, l__self___encoder_layers_encoder_layer_5_mlp_3], Original ATen: [aten._to_copy, aten.abs, aten.add, aten.amax, aten.clamp, aten.div, aten.gelu, aten.round]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_red_fused__to_copy_abs_add_amax_clamp_div_gelu_round_6.run(buf187, buf185, primals_90, primals_91, buf188, buf189, buf190, buf191, 197, 3072, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_91
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf192 = empty_strided_cuda((197, 768), (768, 1), torch.int32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_5_mlp_3], Original ATen: [aten._int_mm]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_tem_fused__int_mm_7.run(buf191, primals_92, buf192, grid=torch._inductor.kernel.mm_common.mm_grid(197, 768, meta1), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_92
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf193 = empty_strided_cuda((1, 197, 768), (151296, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf194 = empty_strided_cuda((1, 197, 1), (197, 1, 1), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf195 = empty_strided_cuda((1, 197, 1), (197, 1, 197), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf197 = reinterpret_tensor(buf195, (1, 197, 1), (197, 1, 1), 0); del buf195  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf198 = empty_strided_cuda((1, 197, 768), (151296, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [add_12, x_29], Original ATen: [aten.add, aten.native_layer_norm]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_per_fused_add_native_layer_norm_8.run(buf197, buf179, buf192, buf190, primals_93, primals_94, primals_95, primals_96, buf193, buf194, buf198, 197, 768, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_94
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_96
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf199 = buf167; del buf167  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [], Original ATen: []
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf198, (197, 768), (768, 1), 0), reinterpret_tensor(primals_97, (768, 2304), (1, 768), 0), out=buf199)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf200 = empty_strided_cuda((3, 197, 1, 768), (151296, 768, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_6_self_attention], Original ATen: [aten.clone]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_poi_fused_clone_1.run(buf199, primals_98, buf200, 453888, grid=grid(453888), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_98
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_6_self_attention], Original ATen: [aten._scaled_dot_product_flash_attention]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf201 = aten._scaled_dot_product_flash_attention.default(reinterpret_tensor(buf200, (1, 12, 197, 64), (0, 64, 768, 1), 0), reinterpret_tensor(buf200, (1, 12, 197, 64), (0, 64, 768, 1), 151296), reinterpret_tensor(buf200, (1, 12, 197, 64), (0, 64, 768, 1), 302592), scale=0.125)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf202 = buf201[0]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf203 = buf201[1]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf204 = buf201[6]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf205 = buf201[7]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del buf201
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf208 = reinterpret_tensor(buf186, (197, 768), (768, 1), 0); del buf186  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf209 = empty_strided_cuda((197, 1), (1, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_6_self_attention], Original ATen: [aten._to_copy, aten.abs, aten.amax, aten.clamp, aten.div, aten.round]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_per_fused__to_copy_abs_amax_clamp_div_round_2.run(buf202, buf208, buf209, 197, 768, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf210 = empty_strided_cuda((197, 768), (768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_6_self_attention], Original ATen: [aten._to_copy, aten.clamp, aten.div, aten.mul, aten.round, aten.view]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_tem_fused__to_copy_clamp_div_mul_round_view_3.run(buf208, primals_99, buf209, buf210, grid=torch._inductor.kernel.mm_common.mm_grid(197, 768, meta0), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf211 = reinterpret_tensor(buf210, (1, 197, 768), (151296, 768, 1), 0); del buf210  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf212 = empty_strided_cuda((1, 197, 1), (197, 1, 1), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf213 = empty_strided_cuda((1, 197, 1), (197, 1, 197), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf215 = reinterpret_tensor(buf213, (1, 197, 1), (197, 1, 1), 0); del buf213  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf216 = empty_strided_cuda((1, 197, 768), (151296, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf217 = reinterpret_tensor(buf209, (1, 197, 1), (197, 1, 1), 0); del buf209  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf218 = reinterpret_tensor(buf208, (1, 197, 768), (151296, 768, 1), 0); del buf208  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_6_mlp_0, x_31, x_32, y_12], Original ATen: [aten._to_copy, aten.abs, aten.add, aten.amax, aten.clamp, aten.clone, aten.div, aten.native_layer_norm, aten.round]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_per_fused__to_copy_abs_add_amax_clamp_clone_div_native_layer_norm_round_4.run(buf211, buf215, primals_100, primals_101, buf193, primals_102, primals_103, buf212, buf216, buf217, buf218, 197, 768, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_101
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_103
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf219 = empty_strided_cuda((197, 3072), (3072, 1), torch.int32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_6_mlp_0], Original ATen: [aten._int_mm]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_tem_fused__int_mm_5.run(buf218, primals_104, buf219, grid=torch._inductor.kernel.mm_common.mm_grid(197, 3072, meta0), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_104
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf220 = empty_strided_cuda((1, 197, 3072), (605184, 3072, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf221 = empty_strided_cuda((1, 197, 3072), (605184, 3072, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf222 = empty_strided_cuda((1, 197, 1), (197, 1, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf223 = buf191; del buf191  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_6_mlp_0, l__self___encoder_layers_encoder_layer_6_mlp_1, l__self___encoder_layers_encoder_layer_6_mlp_3], Original ATen: [aten._to_copy, aten.abs, aten.add, aten.amax, aten.clamp, aten.div, aten.gelu, aten.round]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_red_fused__to_copy_abs_add_amax_clamp_div_gelu_round_6.run(buf219, buf217, primals_105, primals_106, buf220, buf221, buf222, buf223, 197, 3072, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_106
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf224 = empty_strided_cuda((197, 768), (768, 1), torch.int32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_6_mlp_3], Original ATen: [aten._int_mm]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_tem_fused__int_mm_7.run(buf223, primals_107, buf224, grid=torch._inductor.kernel.mm_common.mm_grid(197, 768, meta1), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_107
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf225 = empty_strided_cuda((1, 197, 768), (151296, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf226 = empty_strided_cuda((1, 197, 1), (197, 1, 1), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf227 = empty_strided_cuda((1, 197, 1), (197, 1, 197), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf229 = reinterpret_tensor(buf227, (1, 197, 1), (197, 1, 1), 0); del buf227  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf230 = empty_strided_cuda((1, 197, 768), (151296, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [add_14, x_33], Original ATen: [aten.add, aten.native_layer_norm]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_per_fused_add_native_layer_norm_8.run(buf229, buf211, buf224, buf222, primals_108, primals_109, primals_110, primals_111, buf225, buf226, buf230, 197, 768, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_109
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_111
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf231 = buf199; del buf199  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [], Original ATen: []
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf230, (197, 768), (768, 1), 0), reinterpret_tensor(primals_112, (768, 2304), (1, 768), 0), out=buf231)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf232 = empty_strided_cuda((3, 197, 1, 768), (151296, 768, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_7_self_attention], Original ATen: [aten.clone]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_poi_fused_clone_1.run(buf231, primals_113, buf232, 453888, grid=grid(453888), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_113
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_7_self_attention], Original ATen: [aten._scaled_dot_product_flash_attention]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf233 = aten._scaled_dot_product_flash_attention.default(reinterpret_tensor(buf232, (1, 12, 197, 64), (0, 64, 768, 1), 0), reinterpret_tensor(buf232, (1, 12, 197, 64), (0, 64, 768, 1), 151296), reinterpret_tensor(buf232, (1, 12, 197, 64), (0, 64, 768, 1), 302592), scale=0.125)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf234 = buf233[0]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf235 = buf233[1]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf236 = buf233[6]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf237 = buf233[7]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del buf233
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf240 = reinterpret_tensor(buf218, (197, 768), (768, 1), 0); del buf218  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf241 = empty_strided_cuda((197, 1), (1, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_7_self_attention], Original ATen: [aten._to_copy, aten.abs, aten.amax, aten.clamp, aten.div, aten.round]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_per_fused__to_copy_abs_amax_clamp_div_round_2.run(buf234, buf240, buf241, 197, 768, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf242 = empty_strided_cuda((197, 768), (768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_7_self_attention], Original ATen: [aten._to_copy, aten.clamp, aten.div, aten.mul, aten.round, aten.view]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_tem_fused__to_copy_clamp_div_mul_round_view_3.run(buf240, primals_114, buf241, buf242, grid=torch._inductor.kernel.mm_common.mm_grid(197, 768, meta0), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf243 = reinterpret_tensor(buf242, (1, 197, 768), (151296, 768, 1), 0); del buf242  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf244 = empty_strided_cuda((1, 197, 1), (197, 1, 1), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf245 = empty_strided_cuda((1, 197, 1), (197, 1, 197), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf247 = reinterpret_tensor(buf245, (1, 197, 1), (197, 1, 1), 0); del buf245  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf248 = empty_strided_cuda((1, 197, 768), (151296, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf249 = reinterpret_tensor(buf241, (1, 197, 1), (197, 1, 1), 0); del buf241  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf250 = reinterpret_tensor(buf240, (1, 197, 768), (151296, 768, 1), 0); del buf240  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_7_mlp_0, x_35, x_36, y_14], Original ATen: [aten._to_copy, aten.abs, aten.add, aten.amax, aten.clamp, aten.clone, aten.div, aten.native_layer_norm, aten.round]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_per_fused__to_copy_abs_add_amax_clamp_clone_div_native_layer_norm_round_4.run(buf243, buf247, primals_115, primals_116, buf225, primals_117, primals_118, buf244, buf248, buf249, buf250, 197, 768, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_116
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_118
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf251 = empty_strided_cuda((197, 3072), (3072, 1), torch.int32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_7_mlp_0], Original ATen: [aten._int_mm]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_tem_fused__int_mm_5.run(buf250, primals_119, buf251, grid=torch._inductor.kernel.mm_common.mm_grid(197, 3072, meta0), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_119
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf252 = empty_strided_cuda((1, 197, 3072), (605184, 3072, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf253 = empty_strided_cuda((1, 197, 3072), (605184, 3072, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf254 = empty_strided_cuda((1, 197, 1), (197, 1, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf255 = buf223; del buf223  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_7_mlp_0, l__self___encoder_layers_encoder_layer_7_mlp_1, l__self___encoder_layers_encoder_layer_7_mlp_3], Original ATen: [aten._to_copy, aten.abs, aten.add, aten.amax, aten.clamp, aten.div, aten.gelu, aten.round]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_red_fused__to_copy_abs_add_amax_clamp_div_gelu_round_6.run(buf251, buf249, primals_120, primals_121, buf252, buf253, buf254, buf255, 197, 3072, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_121
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf256 = empty_strided_cuda((197, 768), (768, 1), torch.int32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_7_mlp_3], Original ATen: [aten._int_mm]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_tem_fused__int_mm_7.run(buf255, primals_122, buf256, grid=torch._inductor.kernel.mm_common.mm_grid(197, 768, meta1), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_122
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf257 = empty_strided_cuda((1, 197, 768), (151296, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf258 = empty_strided_cuda((1, 197, 1), (197, 1, 1), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf259 = empty_strided_cuda((1, 197, 1), (197, 1, 197), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf261 = reinterpret_tensor(buf259, (1, 197, 1), (197, 1, 1), 0); del buf259  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf262 = empty_strided_cuda((1, 197, 768), (151296, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [add_16, x_37], Original ATen: [aten.add, aten.native_layer_norm]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_per_fused_add_native_layer_norm_8.run(buf261, buf243, buf256, buf254, primals_123, primals_124, primals_125, primals_126, buf257, buf258, buf262, 197, 768, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_124
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_126
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf263 = buf231; del buf231  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [], Original ATen: []
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf262, (197, 768), (768, 1), 0), reinterpret_tensor(primals_127, (768, 2304), (1, 768), 0), out=buf263)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf264 = empty_strided_cuda((3, 197, 1, 768), (151296, 768, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_8_self_attention], Original ATen: [aten.clone]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_poi_fused_clone_1.run(buf263, primals_128, buf264, 453888, grid=grid(453888), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_128
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_8_self_attention], Original ATen: [aten._scaled_dot_product_flash_attention]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf265 = aten._scaled_dot_product_flash_attention.default(reinterpret_tensor(buf264, (1, 12, 197, 64), (0, 64, 768, 1), 0), reinterpret_tensor(buf264, (1, 12, 197, 64), (0, 64, 768, 1), 151296), reinterpret_tensor(buf264, (1, 12, 197, 64), (0, 64, 768, 1), 302592), scale=0.125)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf266 = buf265[0]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf267 = buf265[1]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf268 = buf265[6]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf269 = buf265[7]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del buf265
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf272 = reinterpret_tensor(buf250, (197, 768), (768, 1), 0); del buf250  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf273 = empty_strided_cuda((197, 1), (1, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_8_self_attention], Original ATen: [aten._to_copy, aten.abs, aten.amax, aten.clamp, aten.div, aten.round]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_per_fused__to_copy_abs_amax_clamp_div_round_2.run(buf266, buf272, buf273, 197, 768, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf274 = empty_strided_cuda((197, 768), (768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_8_self_attention], Original ATen: [aten._to_copy, aten.clamp, aten.div, aten.mul, aten.round, aten.view]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_tem_fused__to_copy_clamp_div_mul_round_view_3.run(buf272, primals_129, buf273, buf274, grid=torch._inductor.kernel.mm_common.mm_grid(197, 768, meta0), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf275 = reinterpret_tensor(buf274, (1, 197, 768), (151296, 768, 1), 0); del buf274  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf276 = empty_strided_cuda((1, 197, 1), (197, 1, 1), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf277 = empty_strided_cuda((1, 197, 1), (197, 1, 197), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf279 = reinterpret_tensor(buf277, (1, 197, 1), (197, 1, 1), 0); del buf277  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf280 = empty_strided_cuda((1, 197, 768), (151296, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf281 = reinterpret_tensor(buf273, (1, 197, 1), (197, 1, 1), 0); del buf273  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf282 = reinterpret_tensor(buf272, (1, 197, 768), (151296, 768, 1), 0); del buf272  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_8_mlp_0, x_39, x_40, y_16], Original ATen: [aten._to_copy, aten.abs, aten.add, aten.amax, aten.clamp, aten.clone, aten.div, aten.native_layer_norm, aten.round]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_per_fused__to_copy_abs_add_amax_clamp_clone_div_native_layer_norm_round_4.run(buf275, buf279, primals_130, primals_131, buf257, primals_132, primals_133, buf276, buf280, buf281, buf282, 197, 768, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_131
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_133
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf283 = empty_strided_cuda((197, 3072), (3072, 1), torch.int32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_8_mlp_0], Original ATen: [aten._int_mm]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_tem_fused__int_mm_5.run(buf282, primals_134, buf283, grid=torch._inductor.kernel.mm_common.mm_grid(197, 3072, meta0), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_134
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf284 = empty_strided_cuda((1, 197, 3072), (605184, 3072, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf285 = empty_strided_cuda((1, 197, 3072), (605184, 3072, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf286 = empty_strided_cuda((1, 197, 1), (197, 1, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf287 = buf255; del buf255  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_8_mlp_0, l__self___encoder_layers_encoder_layer_8_mlp_1, l__self___encoder_layers_encoder_layer_8_mlp_3], Original ATen: [aten._to_copy, aten.abs, aten.add, aten.amax, aten.clamp, aten.div, aten.gelu, aten.round]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_red_fused__to_copy_abs_add_amax_clamp_div_gelu_round_6.run(buf283, buf281, primals_135, primals_136, buf284, buf285, buf286, buf287, 197, 3072, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_136
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf288 = empty_strided_cuda((197, 768), (768, 1), torch.int32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_8_mlp_3], Original ATen: [aten._int_mm]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_tem_fused__int_mm_7.run(buf287, primals_137, buf288, grid=torch._inductor.kernel.mm_common.mm_grid(197, 768, meta1), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_137
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf289 = empty_strided_cuda((1, 197, 768), (151296, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf290 = empty_strided_cuda((1, 197, 1), (197, 1, 1), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf291 = empty_strided_cuda((1, 197, 1), (197, 1, 197), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf293 = reinterpret_tensor(buf291, (1, 197, 1), (197, 1, 1), 0); del buf291  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf294 = empty_strided_cuda((1, 197, 768), (151296, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [add_18, x_41], Original ATen: [aten.add, aten.native_layer_norm]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_per_fused_add_native_layer_norm_8.run(buf293, buf275, buf288, buf286, primals_138, primals_139, primals_140, primals_141, buf289, buf290, buf294, 197, 768, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_139
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_141
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf295 = buf263; del buf263  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [], Original ATen: []
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf294, (197, 768), (768, 1), 0), reinterpret_tensor(primals_142, (768, 2304), (1, 768), 0), out=buf295)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf296 = empty_strided_cuda((3, 197, 1, 768), (151296, 768, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_9_self_attention], Original ATen: [aten.clone]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_poi_fused_clone_1.run(buf295, primals_143, buf296, 453888, grid=grid(453888), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_143
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_9_self_attention], Original ATen: [aten._scaled_dot_product_flash_attention]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf297 = aten._scaled_dot_product_flash_attention.default(reinterpret_tensor(buf296, (1, 12, 197, 64), (0, 64, 768, 1), 0), reinterpret_tensor(buf296, (1, 12, 197, 64), (0, 64, 768, 1), 151296), reinterpret_tensor(buf296, (1, 12, 197, 64), (0, 64, 768, 1), 302592), scale=0.125)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf298 = buf297[0]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf299 = buf297[1]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf300 = buf297[6]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf301 = buf297[7]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del buf297
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf304 = reinterpret_tensor(buf282, (197, 768), (768, 1), 0); del buf282  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf305 = empty_strided_cuda((197, 1), (1, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_9_self_attention], Original ATen: [aten._to_copy, aten.abs, aten.amax, aten.clamp, aten.div, aten.round]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_per_fused__to_copy_abs_amax_clamp_div_round_2.run(buf298, buf304, buf305, 197, 768, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf306 = empty_strided_cuda((197, 768), (768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_9_self_attention], Original ATen: [aten._to_copy, aten.clamp, aten.div, aten.mul, aten.round, aten.view]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_tem_fused__to_copy_clamp_div_mul_round_view_3.run(buf304, primals_144, buf305, buf306, grid=torch._inductor.kernel.mm_common.mm_grid(197, 768, meta0), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf307 = reinterpret_tensor(buf306, (1, 197, 768), (151296, 768, 1), 0); del buf306  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf308 = empty_strided_cuda((1, 197, 1), (197, 1, 1), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf309 = empty_strided_cuda((1, 197, 1), (197, 1, 197), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf311 = reinterpret_tensor(buf309, (1, 197, 1), (197, 1, 1), 0); del buf309  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf312 = empty_strided_cuda((1, 197, 768), (151296, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf313 = reinterpret_tensor(buf305, (1, 197, 1), (197, 1, 1), 0); del buf305  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf314 = reinterpret_tensor(buf304, (1, 197, 768), (151296, 768, 1), 0); del buf304  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_9_mlp_0, x_43, x_44, y_18], Original ATen: [aten._to_copy, aten.abs, aten.add, aten.amax, aten.clamp, aten.clone, aten.div, aten.native_layer_norm, aten.round]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_per_fused__to_copy_abs_add_amax_clamp_clone_div_native_layer_norm_round_4.run(buf307, buf311, primals_145, primals_146, buf289, primals_147, primals_148, buf308, buf312, buf313, buf314, 197, 768, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_146
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_148
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf315 = empty_strided_cuda((197, 3072), (3072, 1), torch.int32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_9_mlp_0], Original ATen: [aten._int_mm]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_tem_fused__int_mm_5.run(buf314, primals_149, buf315, grid=torch._inductor.kernel.mm_common.mm_grid(197, 3072, meta0), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_149
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf316 = empty_strided_cuda((1, 197, 3072), (605184, 3072, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf317 = empty_strided_cuda((1, 197, 3072), (605184, 3072, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf318 = empty_strided_cuda((1, 197, 1), (197, 1, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf319 = buf287; del buf287  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_9_mlp_0, l__self___encoder_layers_encoder_layer_9_mlp_1, l__self___encoder_layers_encoder_layer_9_mlp_3], Original ATen: [aten._to_copy, aten.abs, aten.add, aten.amax, aten.clamp, aten.div, aten.gelu, aten.round]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_red_fused__to_copy_abs_add_amax_clamp_div_gelu_round_6.run(buf315, buf313, primals_150, primals_151, buf316, buf317, buf318, buf319, 197, 3072, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_151
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf320 = empty_strided_cuda((197, 768), (768, 1), torch.int32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_9_mlp_3], Original ATen: [aten._int_mm]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_tem_fused__int_mm_7.run(buf319, primals_152, buf320, grid=torch._inductor.kernel.mm_common.mm_grid(197, 768, meta1), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_152
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf321 = empty_strided_cuda((1, 197, 768), (151296, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf322 = empty_strided_cuda((1, 197, 1), (197, 1, 1), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf323 = empty_strided_cuda((1, 197, 1), (197, 1, 197), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf325 = reinterpret_tensor(buf323, (1, 197, 1), (197, 1, 1), 0); del buf323  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf326 = empty_strided_cuda((1, 197, 768), (151296, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [add_20, x_45], Original ATen: [aten.add, aten.native_layer_norm]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_per_fused_add_native_layer_norm_8.run(buf325, buf307, buf320, buf318, primals_153, primals_154, primals_155, primals_156, buf321, buf322, buf326, 197, 768, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_154
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_156
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf327 = buf295; del buf295  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [], Original ATen: []
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf326, (197, 768), (768, 1), 0), reinterpret_tensor(primals_157, (768, 2304), (1, 768), 0), out=buf327)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf328 = empty_strided_cuda((3, 197, 1, 768), (151296, 768, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_10_self_attention], Original ATen: [aten.clone]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_poi_fused_clone_1.run(buf327, primals_158, buf328, 453888, grid=grid(453888), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_158
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_10_self_attention], Original ATen: [aten._scaled_dot_product_flash_attention]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf329 = aten._scaled_dot_product_flash_attention.default(reinterpret_tensor(buf328, (1, 12, 197, 64), (0, 64, 768, 1), 0), reinterpret_tensor(buf328, (1, 12, 197, 64), (0, 64, 768, 1), 151296), reinterpret_tensor(buf328, (1, 12, 197, 64), (0, 64, 768, 1), 302592), scale=0.125)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf330 = buf329[0]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf331 = buf329[1]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf332 = buf329[6]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf333 = buf329[7]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del buf329
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf336 = reinterpret_tensor(buf314, (197, 768), (768, 1), 0); del buf314  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf337 = empty_strided_cuda((197, 1), (1, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_10_self_attention], Original ATen: [aten._to_copy, aten.abs, aten.amax, aten.clamp, aten.div, aten.round]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_per_fused__to_copy_abs_amax_clamp_div_round_2.run(buf330, buf336, buf337, 197, 768, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf338 = empty_strided_cuda((197, 768), (768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_10_self_attention], Original ATen: [aten._to_copy, aten.clamp, aten.div, aten.mul, aten.round, aten.view]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_tem_fused__to_copy_clamp_div_mul_round_view_3.run(buf336, primals_159, buf337, buf338, grid=torch._inductor.kernel.mm_common.mm_grid(197, 768, meta0), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf339 = reinterpret_tensor(buf338, (1, 197, 768), (151296, 768, 1), 0); del buf338  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf340 = empty_strided_cuda((1, 197, 1), (197, 1, 1), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf341 = empty_strided_cuda((1, 197, 1), (197, 1, 197), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf343 = reinterpret_tensor(buf341, (1, 197, 1), (197, 1, 1), 0); del buf341  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf344 = empty_strided_cuda((1, 197, 768), (151296, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf345 = reinterpret_tensor(buf337, (1, 197, 1), (197, 1, 1), 0); del buf337  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf346 = reinterpret_tensor(buf336, (1, 197, 768), (151296, 768, 1), 0); del buf336  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_10_mlp_0, x_47, x_48, y_20], Original ATen: [aten._to_copy, aten.abs, aten.add, aten.amax, aten.clamp, aten.clone, aten.div, aten.native_layer_norm, aten.round]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_per_fused__to_copy_abs_add_amax_clamp_clone_div_native_layer_norm_round_4.run(buf339, buf343, primals_160, primals_161, buf321, primals_162, primals_163, buf340, buf344, buf345, buf346, 197, 768, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_161
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_163
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf347 = empty_strided_cuda((197, 3072), (3072, 1), torch.int32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_10_mlp_0], Original ATen: [aten._int_mm]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_tem_fused__int_mm_5.run(buf346, primals_164, buf347, grid=torch._inductor.kernel.mm_common.mm_grid(197, 3072, meta0), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_164
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf348 = empty_strided_cuda((1, 197, 3072), (605184, 3072, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf349 = empty_strided_cuda((1, 197, 3072), (605184, 3072, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf350 = empty_strided_cuda((1, 197, 1), (197, 1, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf351 = buf319; del buf319  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_10_mlp_0, l__self___encoder_layers_encoder_layer_10_mlp_1, l__self___encoder_layers_encoder_layer_10_mlp_3], Original ATen: [aten._to_copy, aten.abs, aten.add, aten.amax, aten.clamp, aten.div, aten.gelu, aten.round]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_red_fused__to_copy_abs_add_amax_clamp_div_gelu_round_6.run(buf347, buf345, primals_165, primals_166, buf348, buf349, buf350, buf351, 197, 3072, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_166
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf352 = empty_strided_cuda((197, 768), (768, 1), torch.int32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_10_mlp_3], Original ATen: [aten._int_mm]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_tem_fused__int_mm_7.run(buf351, primals_167, buf352, grid=torch._inductor.kernel.mm_common.mm_grid(197, 768, meta1), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_167
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf353 = empty_strided_cuda((1, 197, 768), (151296, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf354 = empty_strided_cuda((1, 197, 1), (197, 1, 1), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf355 = empty_strided_cuda((1, 197, 1), (197, 1, 197), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf357 = reinterpret_tensor(buf355, (1, 197, 1), (197, 1, 1), 0); del buf355  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf358 = empty_strided_cuda((1, 197, 768), (151296, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [add_22, x_49], Original ATen: [aten.add, aten.native_layer_norm]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_per_fused_add_native_layer_norm_8.run(buf357, buf339, buf352, buf350, primals_168, primals_169, primals_170, primals_171, buf353, buf354, buf358, 197, 768, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_169
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_171
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf359 = buf327; del buf327  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [], Original ATen: []
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         extern_kernels.mm(reinterpret_tensor(buf358, (197, 768), (768, 1), 0), reinterpret_tensor(primals_172, (768, 2304), (1, 768), 0), out=buf359)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf360 = empty_strided_cuda((3, 197, 1, 768), (151296, 768, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_11_self_attention], Original ATen: [aten.clone]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_poi_fused_clone_1.run(buf359, primals_173, buf360, 453888, grid=grid(453888), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del buf359
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_173
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_11_self_attention], Original ATen: [aten._scaled_dot_product_flash_attention]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf361 = aten._scaled_dot_product_flash_attention.default(reinterpret_tensor(buf360, (1, 12, 197, 64), (0, 64, 768, 1), 0), reinterpret_tensor(buf360, (1, 12, 197, 64), (0, 64, 768, 1), 151296), reinterpret_tensor(buf360, (1, 12, 197, 64), (0, 64, 768, 1), 302592), scale=0.125)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf362 = buf361[0]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf363 = buf361[1]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf364 = buf361[6]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf365 = buf361[7]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del buf361
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf368 = reinterpret_tensor(buf346, (197, 768), (768, 1), 0); del buf346  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf369 = empty_strided_cuda((197, 1), (1, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_11_self_attention], Original ATen: [aten._to_copy, aten.abs, aten.amax, aten.clamp, aten.div, aten.round]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_per_fused__to_copy_abs_amax_clamp_div_round_2.run(buf362, buf368, buf369, 197, 768, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf370 = empty_strided_cuda((197, 768), (768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_11_self_attention], Original ATen: [aten._to_copy, aten.clamp, aten.div, aten.mul, aten.round, aten.view]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_tem_fused__to_copy_clamp_div_mul_round_view_3.run(buf368, primals_174, buf369, buf370, grid=torch._inductor.kernel.mm_common.mm_grid(197, 768, meta0), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf371 = reinterpret_tensor(buf370, (1, 197, 768), (151296, 768, 1), 0); del buf370  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf372 = empty_strided_cuda((1, 197, 1), (197, 1, 1), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf373 = empty_strided_cuda((1, 197, 1), (197, 1, 197), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf375 = reinterpret_tensor(buf373, (1, 197, 1), (197, 1, 1), 0); del buf373  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf376 = empty_strided_cuda((1, 197, 768), (151296, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf377 = reinterpret_tensor(buf369, (1, 197, 1), (197, 1, 1), 0); del buf369  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf378 = reinterpret_tensor(buf368, (1, 197, 768), (151296, 768, 1), 0); del buf368  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_11_mlp_0, x_51, x_52, y_22], Original ATen: [aten._to_copy, aten.abs, aten.add, aten.amax, aten.clamp, aten.clone, aten.div, aten.native_layer_norm, aten.round]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_per_fused__to_copy_abs_add_amax_clamp_clone_div_native_layer_norm_round_4.run(buf371, buf375, primals_175, primals_176, buf353, primals_177, primals_178, buf372, buf376, buf377, buf378, 197, 768, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_176
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_178
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf379 = empty_strided_cuda((197, 3072), (3072, 1), torch.int32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_11_mlp_0], Original ATen: [aten._int_mm]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_tem_fused__int_mm_5.run(buf378, primals_179, buf379, grid=torch._inductor.kernel.mm_common.mm_grid(197, 3072, meta0), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del buf378
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_179
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf380 = empty_strided_cuda((1, 197, 3072), (605184, 3072, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf381 = empty_strided_cuda((1, 197, 3072), (605184, 3072, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf382 = empty_strided_cuda((1, 197, 1), (197, 1, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf383 = buf351; del buf351  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_11_mlp_0, l__self___encoder_layers_encoder_layer_11_mlp_1, l__self___encoder_layers_encoder_layer_11_mlp_3], Original ATen: [aten._to_copy, aten.abs, aten.add, aten.amax, aten.clamp, aten.div, aten.gelu, aten.round]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_red_fused__to_copy_abs_add_amax_clamp_div_gelu_round_6.run(buf379, buf377, primals_180, primals_181, buf380, buf381, buf382, buf383, 197, 3072, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_181
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf384 = empty_strided_cuda((197, 768), (768, 1), torch.int32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [l__self___encoder_layers_encoder_layer_11_mlp_3], Original ATen: [aten._int_mm]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_tem_fused__int_mm_7.run(buf383, primals_182, buf384, grid=torch._inductor.kernel.mm_common.mm_grid(197, 768, meta1), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del buf383
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_182
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf385 = empty_strided_cuda((1, 197, 768), (151296, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf386 = empty_strided_cuda((1, 197, 1), (197, 1, 1), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf387 = empty_strided_cuda((1, 197, 1), (197, 1, 197), torch.float32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf389 = reinterpret_tensor(buf387, (1, 197, 1), (197, 1, 1), 0); del buf387  # reuse
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf390 = empty_strided_cuda((1, 197, 768), (151296, 768, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [add_24, x_53], Original ATen: [aten.add, aten.native_layer_norm]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_per_fused_add_native_layer_norm_8.run(buf389, buf371, buf384, buf382, primals_183, primals_184, primals_185, primals_186, buf385, buf386, buf390, 197, 768, grid=grid(197), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_184
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_186
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf391 = empty_strided_cuda((1, 1), (1, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf392 = empty_strided_cuda((1, 768), (768, 1), torch.int8)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [x_55], Original ATen: [aten._to_copy, aten.abs, aten.amax, aten.clamp, aten.div, aten.round]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_per_fused__to_copy_abs_amax_clamp_div_round_9.run(buf390, buf391, buf392, 1, 768, grid=grid(1), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf393 = empty_strided_cuda((1, 1000), (1000, 1), torch.int32)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         buf394 = empty_strided_cuda((1, 1000), (1000, 1), torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         # Source Nodes: [x_55], Original ATen: [aten._int_mm, aten._to_copy, aten.add, aten.clamp, aten.div, aten.mul, aten.round, aten.view]
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         triton_tem_fused__int_mm__to_copy_add_clamp_div_mul_round_view_10.run(buf392, primals_187, buf391, primals_188, primals_189, buf393, buf394, grid=torch._inductor.kernel.mm_common.mm_grid(1, 1000, meta2), stream=stream0)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del buf392
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_187
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]         del primals_189
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     return (buf394, primals_3, primals_5, primals_9, primals_10, primals_12, primals_15, primals_18, primals_20, primals_24, primals_25, primals_27, primals_30, primals_33, primals_35, primals_39, primals_40, primals_42, primals_45, primals_48, primals_50, primals_54, primals_55, primals_57, primals_60, primals_63, primals_65, primals_69, primals_70, primals_72, primals_75, primals_78, primals_80, primals_84, primals_85, primals_87, primals_90, primals_93, primals_95, primals_99, primals_100, primals_102, primals_105, primals_108, primals_110, primals_114, primals_115, primals_117, primals_120, primals_123, primals_125, primals_129, primals_130, primals_132, primals_135, primals_138, primals_140, primals_144, primals_145, primals_147, primals_150, primals_153, primals_155, primals_159, primals_160, primals_162, primals_165, primals_168, primals_170, primals_174, primals_175, primals_177, primals_180, primals_183, primals_185, primals_188, primals_190, buf1, buf2, buf5, reinterpret_tensor(buf6, (197, 768), (768, 1), 0), reinterpret_tensor(buf8, (1, 12, 197, 64), (0, 64, 768, 1), 0), reinterpret_tensor(buf8, (1, 12, 197, 64), (0, 64, 768, 1), 151296), reinterpret_tensor(buf8, (1, 12, 197, 64), (0, 64, 768, 1), 302592), buf11, buf12, buf13, buf19, buf20, buf23, buf24, buf25, buf27, reinterpret_tensor(buf28, (1, 197, 3072), (0, 3072, 1), 0), buf29, buf30, buf32, buf33, buf34, buf37, reinterpret_tensor(buf38, (197, 768), (768, 1), 0), reinterpret_tensor(buf40, (1, 12, 197, 64), (0, 64, 768, 1), 0), reinterpret_tensor(buf40, (1, 12, 197, 64), (0, 64, 768, 1), 151296), reinterpret_tensor(buf40, (1, 12, 197, 64), (0, 64, 768, 1), 302592), buf43, buf44, buf45, buf51, buf52, buf55, buf56, buf57, buf59, reinterpret_tensor(buf60, (1, 197, 3072), (0, 3072, 1), 0), buf61, buf62, buf64, buf65, buf66, buf69, reinterpret_tensor(buf70, (197, 768), (768, 1), 0), reinterpret_tensor(buf72, (1, 12, 197, 64), (0, 64, 768, 1), 0), reinterpret_tensor(buf72, (1, 12, 197, 64), (0, 64, 768, 1), 151296), reinterpret_tensor(buf72, (1, 12, 197, 64), (0, 64, 768, 1), 302592), buf75, buf76, buf77, buf83, buf84, buf87, buf88, buf89, buf91, reinterpret_tensor(buf92, (1, 197, 3072), (0, 3072, 1), 0), buf93, buf94, buf96, buf97, buf98, buf101, reinterpret_tensor(buf102, (197, 768), (768, 1), 0), reinterpret_tensor(buf104, (1, 12, 197, 64), (0, 64, 768, 1), 0), reinterpret_tensor(buf104, (1, 12, 197, 64), (0, 64, 768, 1), 151296), reinterpret_tensor(buf104, (1, 12, 197, 64), (0, 64, 768, 1), 302592), buf107, buf108, buf109, buf115, buf116, buf119, buf120, buf121, buf123, reinterpret_tensor(buf124, (1, 197, 3072), (0, 3072, 1), 0), buf125, buf126, buf128, buf129, buf130, buf133, reinterpret_tensor(buf134, (197, 768), (768, 1), 0), reinterpret_tensor(buf136, (1, 12, 197, 64), (0, 64, 768, 1), 0), reinterpret_tensor(buf136, (1, 12, 197, 64), (0, 64, 768, 1), 151296), reinterpret_tensor(buf136, (1, 12, 197, 64), (0, 64, 768, 1), 302592), buf139, buf140, buf141, buf147, buf148, buf151, buf152, buf153, buf155, reinterpret_tensor(buf156, (1, 197, 3072), (0, 3072, 1), 0), buf157, buf158, buf160, buf161, buf162, buf165, reinterpret_tensor(buf166, (197, 768), (768, 1), 0), reinterpret_tensor(buf168, (1, 12, 197, 64), (0, 64, 768, 1), 0), reinterpret_tensor(buf168, (1, 12, 197, 64), (0, 64, 768, 1), 151296), reinterpret_tensor(buf168, (1, 12, 197, 64), (0, 64, 768, 1), 302592), buf171, buf172, buf173, buf179, buf180, buf183, buf184, buf185, buf187, reinterpret_tensor(buf188, (1, 197, 3072), (0, 3072, 1), 0), buf189, buf190, buf192, buf193, buf194, buf197, reinterpret_tensor(buf198, (197, 768), (768, 1), 0), reinterpret_tensor(buf200, (1, 12, 197, 64), (0, 64, 768, 1), 0), reinterpret_tensor(buf200, (1, 12, 197, 64), (0, 64, 768, 1), 151296), reinterpret_tensor(buf200, (1, 12, 197, 64), (0, 64, 768, 1), 302592), buf203, buf204, buf205, buf211, buf212, buf215, buf216, buf217, buf219, reinterpret_tensor(buf220, (1, 197, 3072), (0, 3072, 1), 0), buf221, buf222, buf224, buf225, buf226, buf229, reinterpret_tensor(buf230, (197, 768), (768, 1), 0), reinterpret_tensor(buf232, (1, 12, 197, 64), (0, 64, 768, 1), 0), reinterpret_tensor(buf232, (1, 12, 197, 64), (0, 64, 768, 1), 151296), reinterpret_tensor(buf232, (1, 12, 197, 64), (0, 64, 768, 1), 302592), buf235, buf236, buf237, buf243, buf244, buf247, buf248, buf249, buf251, reinterpret_tensor(buf252, (1, 197, 3072), (0, 3072, 1), 0), buf253, buf254, buf256, buf257, buf258, buf261, reinterpret_tensor(buf262, (197, 768), (768, 1), 0), reinterpret_tensor(buf264, (1, 12, 197, 64), (0, 64, 768, 1), 0), reinterpret_tensor(buf264, (1, 12, 197, 64), (0, 64, 768, 1), 151296), reinterpret_tensor(buf264, (1, 12, 197, 64), (0, 64, 768, 1), 302592), buf267, buf268, buf269, buf275, buf276, buf279, buf280, buf281, buf283, reinterpret_tensor(buf284, (1, 197, 3072), (0, 3072, 1), 0), buf285, buf286, buf288, buf289, buf290, buf293, reinterpret_tensor(buf294, (197, 768), (768, 1), 0), reinterpret_tensor(buf296, (1, 12, 197, 64), (0, 64, 768, 1), 0), reinterpret_tensor(buf296, (1, 12, 197, 64), (0, 64, 768, 1), 151296), reinterpret_tensor(buf296, (1, 12, 197, 64), (0, 64, 768, 1), 302592), buf299, buf300, buf301, buf307, buf308, buf311, buf312, buf313, buf315, reinterpret_tensor(buf316, (1, 197, 3072), (0, 3072, 1), 0), buf317, buf318, buf320, buf321, buf322, buf325, reinterpret_tensor(buf326, (197, 768), (768, 1), 0), reinterpret_tensor(buf328, (1, 12, 197, 64), (0, 64, 768, 1), 0), reinterpret_tensor(buf328, (1, 12, 197, 64), (0, 64, 768, 1), 151296), reinterpret_tensor(buf328, (1, 12, 197, 64), (0, 64, 768, 1), 302592), buf331, buf332, buf333, buf339, buf340, buf343, buf344, buf345, buf347, reinterpret_tensor(buf348, (1, 197, 3072), (0, 3072, 1), 0), buf349, buf350, buf352, buf353, buf354, buf357, reinterpret_tensor(buf358, (197, 768), (768, 1), 0), reinterpret_tensor(buf360, (1, 12, 197, 64), (0, 64, 768, 1), 0), reinterpret_tensor(buf360, (1, 12, 197, 64), (0, 64, 768, 1), 151296), reinterpret_tensor(buf360, (1, 12, 197, 64), (0, 64, 768, 1), 302592), buf363, buf364, buf365, buf371, buf372, buf375, buf376, buf377, buf379, reinterpret_tensor(buf380, (1, 197, 3072), (0, 3072, 1), 0), buf381, buf382, buf384, buf385, buf386, buf389, reinterpret_tensor(buf390, (1, 768), (0, 1), 0), buf391, buf393, buf362, reinterpret_tensor(primals_172, (2304, 768), (768, 1), 0), buf330, reinterpret_tensor(primals_157, (2304, 768), (768, 1), 0), buf298, reinterpret_tensor(primals_142, (2304, 768), (768, 1), 0), buf266, reinterpret_tensor(primals_127, (2304, 768), (768, 1), 0), buf234, reinterpret_tensor(primals_112, (2304, 768), (768, 1), 0), buf202, reinterpret_tensor(primals_97, (2304, 768), (768, 1), 0), buf170, reinterpret_tensor(primals_82, (2304, 768), (768, 1), 0), buf138, reinterpret_tensor(primals_67, (2304, 768), (768, 1), 0), buf106, reinterpret_tensor(primals_52, (2304, 768), (768, 1), 0), buf74, reinterpret_tensor(primals_37, (2304, 768), (768, 1), 0), buf42, reinterpret_tensor(primals_22, (2304, 768), (768, 1), 0), buf10, reinterpret_tensor(primals_7, (2304, 768), (768, 1), 0), )
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] def benchmark_compiled_module(times=10, repeat=10):
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     from torch._dynamo.testing import rand_strided
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     from torch._inductor.utils import print_performance
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_1 = rand_strided((1, 1, 768), (768, 768, 1), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_2 = rand_strided((1, 197, 768), (151296, 768, 1), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_3 = rand_strided((768, 3, 16, 16), (768, 256, 16, 1), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_4 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_5 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_6 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_7 = rand_strided((2304, 768), (768, 1), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_8 = rand_strided((2304, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_9 = rand_strided((768, 768), (1, 768), device='cuda:0', dtype=torch.int8)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_10 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_11 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_12 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_13 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_14 = rand_strided((768, 3072), (1, 768), device='cuda:0', dtype=torch.int8)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_15 = rand_strided((3072, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_16 = rand_strided((3072, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_17 = rand_strided((3072, 768), (1, 3072), device='cuda:0', dtype=torch.int8)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_18 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_19 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_20 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_21 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_22 = rand_strided((2304, 768), (768, 1), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_23 = rand_strided((2304, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_24 = rand_strided((768, 768), (1, 768), device='cuda:0', dtype=torch.int8)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_25 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_26 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_27 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_28 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_29 = rand_strided((768, 3072), (1, 768), device='cuda:0', dtype=torch.int8)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_30 = rand_strided((3072, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_31 = rand_strided((3072, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_32 = rand_strided((3072, 768), (1, 3072), device='cuda:0', dtype=torch.int8)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_33 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_34 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_35 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_36 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_37 = rand_strided((2304, 768), (768, 1), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_38 = rand_strided((2304, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_39 = rand_strided((768, 768), (1, 768), device='cuda:0', dtype=torch.int8)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_40 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_41 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_42 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_43 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_44 = rand_strided((768, 3072), (1, 768), device='cuda:0', dtype=torch.int8)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_45 = rand_strided((3072, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_46 = rand_strided((3072, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_47 = rand_strided((3072, 768), (1, 3072), device='cuda:0', dtype=torch.int8)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_48 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_49 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_50 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_51 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_52 = rand_strided((2304, 768), (768, 1), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_53 = rand_strided((2304, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_54 = rand_strided((768, 768), (1, 768), device='cuda:0', dtype=torch.int8)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_55 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_56 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_57 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_58 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_59 = rand_strided((768, 3072), (1, 768), device='cuda:0', dtype=torch.int8)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_60 = rand_strided((3072, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_61 = rand_strided((3072, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_62 = rand_strided((3072, 768), (1, 3072), device='cuda:0', dtype=torch.int8)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_63 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_64 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_65 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_66 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_67 = rand_strided((2304, 768), (768, 1), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_68 = rand_strided((2304, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_69 = rand_strided((768, 768), (1, 768), device='cuda:0', dtype=torch.int8)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_70 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_71 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_72 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_73 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_74 = rand_strided((768, 3072), (1, 768), device='cuda:0', dtype=torch.int8)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_75 = rand_strided((3072, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_76 = rand_strided((3072, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_77 = rand_strided((3072, 768), (1, 3072), device='cuda:0', dtype=torch.int8)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_78 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_79 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_80 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_81 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_82 = rand_strided((2304, 768), (768, 1), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_83 = rand_strided((2304, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_84 = rand_strided((768, 768), (1, 768), device='cuda:0', dtype=torch.int8)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_85 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_86 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_87 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_88 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_89 = rand_strided((768, 3072), (1, 768), device='cuda:0', dtype=torch.int8)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_90 = rand_strided((3072, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_91 = rand_strided((3072, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_92 = rand_strided((3072, 768), (1, 3072), device='cuda:0', dtype=torch.int8)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_93 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_94 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_95 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_96 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_97 = rand_strided((2304, 768), (768, 1), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_98 = rand_strided((2304, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_99 = rand_strided((768, 768), (1, 768), device='cuda:0', dtype=torch.int8)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_100 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_101 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_102 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_103 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_104 = rand_strided((768, 3072), (1, 768), device='cuda:0', dtype=torch.int8)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_105 = rand_strided((3072, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_106 = rand_strided((3072, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_107 = rand_strided((3072, 768), (1, 3072), device='cuda:0', dtype=torch.int8)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_108 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_109 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_110 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_111 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_112 = rand_strided((2304, 768), (768, 1), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_113 = rand_strided((2304, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_114 = rand_strided((768, 768), (1, 768), device='cuda:0', dtype=torch.int8)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_115 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_116 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_117 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_118 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_119 = rand_strided((768, 3072), (1, 768), device='cuda:0', dtype=torch.int8)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_120 = rand_strided((3072, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_121 = rand_strided((3072, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_122 = rand_strided((3072, 768), (1, 3072), device='cuda:0', dtype=torch.int8)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_123 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_124 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_125 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_126 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_127 = rand_strided((2304, 768), (768, 1), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_128 = rand_strided((2304, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_129 = rand_strided((768, 768), (1, 768), device='cuda:0', dtype=torch.int8)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_130 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_131 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_132 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_133 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_134 = rand_strided((768, 3072), (1, 768), device='cuda:0', dtype=torch.int8)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_135 = rand_strided((3072, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_136 = rand_strided((3072, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_137 = rand_strided((3072, 768), (1, 3072), device='cuda:0', dtype=torch.int8)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_138 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_139 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_140 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_141 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_142 = rand_strided((2304, 768), (768, 1), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_143 = rand_strided((2304, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_144 = rand_strided((768, 768), (1, 768), device='cuda:0', dtype=torch.int8)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_145 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_146 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_147 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_148 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_149 = rand_strided((768, 3072), (1, 768), device='cuda:0', dtype=torch.int8)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_150 = rand_strided((3072, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_151 = rand_strided((3072, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_152 = rand_strided((3072, 768), (1, 3072), device='cuda:0', dtype=torch.int8)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_153 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_154 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_155 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_156 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_157 = rand_strided((2304, 768), (768, 1), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_158 = rand_strided((2304, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_159 = rand_strided((768, 768), (1, 768), device='cuda:0', dtype=torch.int8)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_160 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_161 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_162 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_163 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_164 = rand_strided((768, 3072), (1, 768), device='cuda:0', dtype=torch.int8)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_165 = rand_strided((3072, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_166 = rand_strided((3072, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_167 = rand_strided((3072, 768), (1, 3072), device='cuda:0', dtype=torch.int8)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_168 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_169 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_170 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_171 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_172 = rand_strided((2304, 768), (768, 1), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_173 = rand_strided((2304, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_174 = rand_strided((768, 768), (1, 768), device='cuda:0', dtype=torch.int8)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_175 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_176 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_177 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_178 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_179 = rand_strided((768, 3072), (1, 768), device='cuda:0', dtype=torch.int8)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_180 = rand_strided((3072, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_181 = rand_strided((3072, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_182 = rand_strided((3072, 768), (1, 3072), device='cuda:0', dtype=torch.int8)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_183 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_184 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_185 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_186 = rand_strided((768, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_187 = rand_strided((768, 1000), (1, 768), device='cuda:0', dtype=torch.int8)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_188 = rand_strided((1000, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_189 = rand_strided((1000, ), (1, ), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     primals_190 = rand_strided((1, 3, 224, 224), (150528, 50176, 224, 1), device='cuda:0', dtype=torch.bfloat16)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     fn = lambda: call([primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42, primals_43, primals_44, primals_45, primals_46, primals_47, primals_48, primals_49, primals_50, primals_51, primals_52, primals_53, primals_54, primals_55, primals_56, primals_57, primals_58, primals_59, primals_60, primals_61, primals_62, primals_63, primals_64, primals_65, primals_66, primals_67, primals_68, primals_69, primals_70, primals_71, primals_72, primals_73, primals_74, primals_75, primals_76, primals_77, primals_78, primals_79, primals_80, primals_81, primals_82, primals_83, primals_84, primals_85, primals_86, primals_87, primals_88, primals_89, primals_90, primals_91, primals_92, primals_93, primals_94, primals_95, primals_96, primals_97, primals_98, primals_99, primals_100, primals_101, primals_102, primals_103, primals_104, primals_105, primals_106, primals_107, primals_108, primals_109, primals_110, primals_111, primals_112, primals_113, primals_114, primals_115, primals_116, primals_117, primals_118, primals_119, primals_120, primals_121, primals_122, primals_123, primals_124, primals_125, primals_126, primals_127, primals_128, primals_129, primals_130, primals_131, primals_132, primals_133, primals_134, primals_135, primals_136, primals_137, primals_138, primals_139, primals_140, primals_141, primals_142, primals_143, primals_144, primals_145, primals_146, primals_147, primals_148, primals_149, primals_150, primals_151, primals_152, primals_153, primals_154, primals_155, primals_156, primals_157, primals_158, primals_159, primals_160, primals_161, primals_162, primals_163, primals_164, primals_165, primals_166, primals_167, primals_168, primals_169, primals_170, primals_171, primals_172, primals_173, primals_174, primals_175, primals_176, primals_177, primals_178, primals_179, primals_180, primals_181, primals_182, primals_183, primals_184, primals_185, primals_186, primals_187, primals_188, primals_189, primals_190])
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     return print_performance(fn, times=times, repeat=repeat)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] if __name__ == "__main__":
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     from torch._inductor.wrapper_benchmark import compiled_module_main
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code]     compiled_module_main('None', benchmark_compiled_module)
V0315 17:54:37.217000 140019365857088 torch/_inductor/graph.py:1258] [0/0] [__output_code] 
I0315 17:54:37.218000 140019365857088 torch/_inductor/graph.py:1264] [0/0] [__output_code] Output code written to: /tmp/torchinductor_cpuhrsch/lw/clwqhl3l3o6uulco4bcsgsibw4u2pmdfigkgl3hm4hgps4q6bu6p.py
